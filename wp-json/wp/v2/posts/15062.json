{"id":15062,"date":"2024-06-19T15:40:48","date_gmt":"2024-06-19T15:40:48","guid":{"rendered":"https:\/\/www.artificialintelligence-news.com\/?p=15062"},"modified":"2024-06-19T15:40:50","modified_gmt":"2024-06-19T15:40:50","slug":"meta-unveils-ai-models-multi-modal-processing-music-generation-more","status":"publish","type":"post","link":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/","title":{"rendered":"Meta unveils five AI models for multi-modal processing, music generation, and more"},"content":{"rendered":"\n<p>Meta has <a href=\"https:\/\/about.fb.com\/news\/2024\/06\/releasing-new-ai-research-models-to-accelerate-innovation-at-scale\/\">unveiled<\/a> five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.<\/p>\n\n\n\n<p>The releases come from Meta&#8217;s Fundamental AI Research (FAIR) team which has focused on advancing AI through open research and collaboration for over a decade. As AI rapidly innovates, Meta believes working with the global community is crucial.<\/p>\n\n\n\n<p>&#8220;By publicly sharing this research, we hope to inspire iterations and ultimately help advance AI in a responsible way,&#8221; said Meta.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Chameleon: Multi-modal text and image processing<\/h4>\n\n\n\n<p>Among the releases are key components of Meta&#8217;s &#8216;Chameleon&#8217; models under a research license. Chameleon is a family of multi-modal models that can understand and generate both text and images simultaneously\u2014unlike most large language models which are typically unimodal.<\/p>\n\n\n\n<p>&#8220;Just as humans can process the words and images simultaneously, Chameleon can process and deliver both image and text at the same time,&#8221; explained Meta. &#8220;Chameleon can take any combination of text and images as input and also output any combination of text and images.&#8221;<\/p>\n\n\n\n<p>Potential use cases are virtually limitless from generating creative captions to prompting new scenes with text and images.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Multi-token prediction for faster language model training<\/h4>\n\n\n\n<p>Meta has also released pretrained models for code completion that use &#8216;multi-token prediction&#8217; under a non-commercial research license. Traditional language model training is inefficient by predicting just the next word. Multi-token models can predict multiple future words simultaneously to train faster.<\/p>\n\n\n\n<p>&#8220;While [the one-word] approach is simple and scalable, it&#8217;s also inefficient. It requires several orders of magnitude more text than what children need to learn the same degree of language fluency,&#8221; said Meta.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">JASCO: Enhanced text-to-music model<\/h4>\n\n\n\n<p>On the creative side, Meta&#8217;s JASCO allows generating music clips from text while affording more control by accepting inputs like chords and beats.<\/p>\n\n\n\n<p>&#8220;While existing text-to-music models like MusicGen rely mainly on text inputs for music generation, our new model, JASCO, is capable of accepting various inputs, such as chords or beat, to improve control over generated music outputs,&#8221; explained Meta.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">AudioSeal: Detecting AI-generated speech<\/h4>\n\n\n\n<p>Meta claims AudioSeal is the first audio watermarking system designed to detect AI-generated speech. It can pinpoint the specific segments generated by AI within larger audio clips up to 485x faster than previous methods.<\/p>\n\n\n\n<p>&#8220;AudioSeal is being released under a commercial license. It&#8217;s just one of several lines of responsible research we have shared to help prevent the misuse of generative AI tools,&#8221; said Meta.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Improving text-to-image diversity<\/h4>\n\n\n\n<p>Another important release aims to improve the diversity of text-to-image models which can often exhibit geographical and cultural biases.<\/p>\n\n\n\n<p>Meta developed automatic indicators to evaluate potential geographical disparities and conducted a large 65,000+ annotation study to understand how people globally perceive geographic representation.<\/p>\n\n\n\n<p>&#8220;This enables more diversity and better representation in AI-generated images,&#8221; said Meta. The relevant code and annotations have been released to help improve diversity across generative models.<\/p>\n\n\n\n<p>By publicly sharing these groundbreaking models, Meta says it hopes to foster collaboration and drive innovation within the AI community.<\/p>\n\n\n\n<p><em>(Photo by <a href=\"https:\/\/unsplash.com\/@solomin_d?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Dima Solomin<\/a>)<\/em><\/p>\n\n\n\n<p><strong>See also: <\/strong><a href=\"https:\/\/www.artificialintelligence-news.com\/2024\/06\/17\/nvidia-presents-latest-advancements-visual-ai\/\"><strong>NVIDIA presents latest advancements in visual AI<\/strong><\/a><\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><a href=\"https:\/\/www.ai-expo.net\/\"><img loading=\"lazy\" decoding=\"async\" width=\"728\" height=\"90\" src=\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/sites\/9\/2022\/04\/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" srcset=\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2022\/04\/ai-expo-world-728x-90-01.png 728w, https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2022\/04\/ai-expo-world-728x-90-01-300x37.png 300w, https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2022\/04\/ai-expo-world-728x-90-01-380x47.png 380w, https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2022\/04\/ai-expo-world-728x-90-01-350x43.png 350w, https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2022\/04\/ai-expo-world-728x-90-01-100x12.png 100w, https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2022\/04\/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"auto, (max-width: 728px) 100vw, 728px\" \/><\/a><\/figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?<\/strong> Check out<a href=\"https:\/\/www.ai-expo.net\/\"> AI &amp; Big Data Expo<\/a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https:\/\/intelligentautomation-conference.com\/northamerica\/\">Intelligent Automation Conference<\/a>, <a href=\"https:\/\/www.blockchain-expo.com\/\">BlockX<\/a>,<a href=\"https:\/\/digitaltransformation-week.com\/\"> Digital Transformation Week<\/a>, and <a href=\"https:\/\/www.cybersecuritycloudexpo.com\/\">Cyber Security &amp; Cloud Expo<\/a>.<\/p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https:\/\/techforge.pub\/upcoming-events\/\">here<\/a>.<\/p>\n","protected":false},"excerpt":{"rendered":"<p>Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems. The releases come from Meta&#8217;s Fundamental AI Research (FAIR) team which has focused on advancing AI through open research<a class=\"excerpt-read-more\" href=\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\" title=\"ReadMeta unveils five AI models for multi-modal processing, music generation, and more\">&#8230; Read more &raquo;<\/a><\/p>\n","protected":false},"author":1570,"featured_media":15064,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"_acf_changed":false,"om_disable_all_campaigns":false,"_monsterinsights_skip_tracking":false,"_monsterinsights_sitenote_active":false,"_monsterinsights_sitenote_note":"","_monsterinsights_sitenote_category":0,"_uf_show_specific_survey":0,"_uf_disable_surveys":false,"footnotes":""},"categories":[1,1900,1906,617],"tags":[186,192,2980,2978,760,2979,1961,2977,2964,2981,1962,2200],"ppma_author":[2401],"class_list":["post-15062","post","type-post","status-publish","format-standard","has-post-thumbnail","hentry","category-artificial-intelligence","category-ai-companies","category-development","category-meta-facebook","tag-ai","tag-artificial-intelligence","tag-audioseal","tag-chameleon","tag-fair","tag-jasco","tag-meta","tag-meta-ai","tag-models","tag-music-generation","tag-open-source","tag-text-to-image"],"acf":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO plugin v24.1 - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>Meta unveils five AI models for multi-modal processing, music generation, and more<\/title>\n<meta name=\"description\" content=\"Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.\" \/>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\" \/>\n<meta property=\"og:locale\" content=\"en_GB\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"Meta unveils five AI models for multi-modal processing, music generation, and more\" \/>\n<meta property=\"og:description\" content=\"Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\" \/>\n<meta property=\"og:site_name\" content=\"AI News\" \/>\n<meta property=\"article:publisher\" content=\"https:\/\/www.facebook.com\/AITechNews\/\" \/>\n<meta property=\"article:published_time\" content=\"2024-06-19T15:40:48+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2024-06-19T15:40:50+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg\" \/>\n\t<meta property=\"og:image:width\" content=\"2210\" \/>\n\t<meta property=\"og:image:height\" content=\"1600\" \/>\n\t<meta property=\"og:image:type\" content=\"image\/jpeg\" \/>\n<meta name=\"author\" content=\"Ryan Daws\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:creator\" content=\"@Gadget_Ry\" \/>\n<meta name=\"twitter:site\" content=\"@ai_technews\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"Ryan Daws\" \/>\n\t<meta name=\"twitter:label2\" content=\"Estimated reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"3 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"Article\",\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#article\",\"isPartOf\":{\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\"},\"author\":{\"name\":\"Ryan Daws\",\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#\/schema\/person\/e4d76ff18520c27fd0713eff05f814ed\"},\"headline\":\"Meta unveils five AI models for multi-modal processing, music generation, and more\",\"datePublished\":\"2024-06-19T15:40:48+00:00\",\"dateModified\":\"2024-06-19T15:40:50+00:00\",\"mainEntityOfPage\":{\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\"},\"wordCount\":597,\"commentCount\":0,\"publisher\":{\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#organization\"},\"image\":{\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage\"},\"thumbnailUrl\":\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg\",\"keywords\":[\"ai\",\"artificial intelligence\",\"audioseal\",\"chameleon\",\"fair\",\"jasco\",\"meta\",\"meta ai\",\"models\",\"music generation\",\"open source\",\"text-to-image\"],\"articleSection\":[\"Artificial Intelligence\",\"Companies\",\"Development\",\"Meta (Facebook)\"],\"inLanguage\":\"en-GB\",\"potentialAction\":[{\"@type\":\"CommentAction\",\"name\":\"Comment\",\"target\":[\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#respond\"]}]},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\",\"url\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\",\"name\":\"Meta unveils five AI models for multi-modal processing, music generation, and more\",\"isPartOf\":{\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage\"},\"image\":{\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage\"},\"thumbnailUrl\":\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg\",\"datePublished\":\"2024-06-19T15:40:48+00:00\",\"dateModified\":\"2024-06-19T15:40:50+00:00\",\"description\":\"Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.\",\"breadcrumb\":{\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#breadcrumb\"},\"inLanguage\":\"en-GB\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/\"]}]},{\"@type\":\"ImageObject\",\"inLanguage\":\"en-GB\",\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage\",\"url\":\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg\",\"contentUrl\":\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg\",\"width\":2210,\"height\":1600},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/www.artificialintelligence-news.com\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Meta unveils five AI models for multi-modal processing, music generation, and more\"}]},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#website\",\"url\":\"https:\/\/www.ianj52.sg-host.com\/\",\"name\":\"AI News\",\"description\":\"Artificial Intelligence News\",\"publisher\":{\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#organization\"},\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/www.ianj52.sg-host.com\/?s={search_term_string}\"},\"query-input\":{\"@type\":\"PropertyValueSpecification\",\"valueRequired\":true,\"valueName\":\"search_term_string\"}}],\"inLanguage\":\"en-GB\"},{\"@type\":\"Organization\",\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#organization\",\"name\":\"AI News\",\"url\":\"https:\/\/www.ianj52.sg-host.com\/\",\"logo\":{\"@type\":\"ImageObject\",\"inLanguage\":\"en-GB\",\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#\/schema\/logo\/image\/\",\"url\":\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2020\/03\/ai-newsv4-2-svg.png\",\"contentUrl\":\"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2020\/03\/ai-newsv4-2-svg.png\",\"width\":400,\"height\":78,\"caption\":\"AI News\"},\"image\":{\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#\/schema\/logo\/image\/\"},\"sameAs\":[\"https:\/\/www.facebook.com\/AITechNews\/\",\"https:\/\/x.com\/ai_technews\",\"https:\/\/www.linkedin.com\/groups\/1906826\/\"]},{\"@type\":\"Person\",\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#\/schema\/person\/e4d76ff18520c27fd0713eff05f814ed\",\"name\":\"Ryan Daws\",\"image\":{\"@type\":\"ImageObject\",\"inLanguage\":\"en-GB\",\"@id\":\"https:\/\/www.ianj52.sg-host.com\/#\/schema\/person\/image\/0a89168c3b9fc190f9bdbce571d2fa5f\",\"url\":\"https:\/\/secure.gravatar.com\/avatar\/b8c5d238e1fddd55d8a0064f1a534ba5?s=96&d=mm&r=g\",\"contentUrl\":\"https:\/\/secure.gravatar.com\/avatar\/b8c5d238e1fddd55d8a0064f1a534ba5?s=96&d=mm&r=g\",\"caption\":\"Ryan Daws\"},\"description\":\"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and\/or Mastodon (@gadgetry@techhub.social)\",\"sameAs\":[\"https:\/\/twitter.com\/gadget_ry\",\"https:\/\/x.com\/Gadget_Ry\"],\"url\":\"https:\/\/www.artificialintelligence-news.com\/news\/author\/ryan\/\"}]}<\/script>\n<!-- \/ Yoast SEO plugin. -->","yoast_head_json":{"title":"Meta unveils five AI models for multi-modal processing, music generation, and more","description":"Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/","og_locale":"en_GB","og_type":"article","og_title":"Meta unveils five AI models for multi-modal processing, music generation, and more","og_description":"Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.","og_url":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/","og_site_name":"AI News","article_publisher":"https:\/\/www.facebook.com\/AITechNews\/","article_published_time":"2024-06-19T15:40:48+00:00","article_modified_time":"2024-06-19T15:40:50+00:00","og_image":[{"width":2210,"height":1600,"url":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg","type":"image\/jpeg"}],"author":"Ryan Daws","twitter_card":"summary_large_image","twitter_creator":"@Gadget_Ry","twitter_site":"@ai_technews","twitter_misc":{"Written by":"Ryan Daws","Estimated reading time":"3 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"Article","@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#article","isPartOf":{"@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/"},"author":{"name":"Ryan Daws","@id":"https:\/\/www.ianj52.sg-host.com\/#\/schema\/person\/e4d76ff18520c27fd0713eff05f814ed"},"headline":"Meta unveils five AI models for multi-modal processing, music generation, and more","datePublished":"2024-06-19T15:40:48+00:00","dateModified":"2024-06-19T15:40:50+00:00","mainEntityOfPage":{"@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/"},"wordCount":597,"commentCount":0,"publisher":{"@id":"https:\/\/www.ianj52.sg-host.com\/#organization"},"image":{"@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage"},"thumbnailUrl":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg","keywords":["ai","artificial intelligence","audioseal","chameleon","fair","jasco","meta","meta ai","models","music generation","open source","text-to-image"],"articleSection":["Artificial Intelligence","Companies","Development","Meta (Facebook)"],"inLanguage":"en-GB","potentialAction":[{"@type":"CommentAction","name":"Comment","target":["https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#respond"]}]},{"@type":"WebPage","@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/","url":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/","name":"Meta unveils five AI models for multi-modal processing, music generation, and more","isPartOf":{"@id":"https:\/\/www.ianj52.sg-host.com\/#website"},"primaryImageOfPage":{"@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage"},"image":{"@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage"},"thumbnailUrl":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg","datePublished":"2024-06-19T15:40:48+00:00","dateModified":"2024-06-19T15:40:50+00:00","description":"Meta has unveiled five major new AI models and research, including multi-modal systems that can process both text and images, next-gen language models, music generation, AI speech detection, and efforts to improve diversity in AI systems.","breadcrumb":{"@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#breadcrumb"},"inLanguage":"en-GB","potentialAction":[{"@type":"ReadAction","target":["https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/"]}]},{"@type":"ImageObject","inLanguage":"en-GB","@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#primaryimage","url":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg","contentUrl":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2024\/06\/meta-ai-models-open-source-chameleon-multi-modal-jasco-artificial-intelligence.jpg","width":2210,"height":1600},{"@type":"BreadcrumbList","@id":"https:\/\/www.artificialintelligence-news.com\/news\/meta-unveils-ai-models-multi-modal-processing-music-generation-more\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/www.artificialintelligence-news.com\/"},{"@type":"ListItem","position":2,"name":"Meta unveils five AI models for multi-modal processing, music generation, and more"}]},{"@type":"WebSite","@id":"https:\/\/www.ianj52.sg-host.com\/#website","url":"https:\/\/www.ianj52.sg-host.com\/","name":"AI News","description":"Artificial Intelligence News","publisher":{"@id":"https:\/\/www.ianj52.sg-host.com\/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/www.ianj52.sg-host.com\/?s={search_term_string}"},"query-input":{"@type":"PropertyValueSpecification","valueRequired":true,"valueName":"search_term_string"}}],"inLanguage":"en-GB"},{"@type":"Organization","@id":"https:\/\/www.ianj52.sg-host.com\/#organization","name":"AI News","url":"https:\/\/www.ianj52.sg-host.com\/","logo":{"@type":"ImageObject","inLanguage":"en-GB","@id":"https:\/\/www.ianj52.sg-host.com\/#\/schema\/logo\/image\/","url":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2020\/03\/ai-newsv4-2-svg.png","contentUrl":"https:\/\/www.artificialintelligence-news.com\/wp-content\/uploads\/2020\/03\/ai-newsv4-2-svg.png","width":400,"height":78,"caption":"AI News"},"image":{"@id":"https:\/\/www.ianj52.sg-host.com\/#\/schema\/logo\/image\/"},"sameAs":["https:\/\/www.facebook.com\/AITechNews\/","https:\/\/x.com\/ai_technews","https:\/\/www.linkedin.com\/groups\/1906826\/"]},{"@type":"Person","@id":"https:\/\/www.ianj52.sg-host.com\/#\/schema\/person\/e4d76ff18520c27fd0713eff05f814ed","name":"Ryan Daws","image":{"@type":"ImageObject","inLanguage":"en-GB","@id":"https:\/\/www.ianj52.sg-host.com\/#\/schema\/person\/image\/0a89168c3b9fc190f9bdbce571d2fa5f","url":"https:\/\/secure.gravatar.com\/avatar\/b8c5d238e1fddd55d8a0064f1a534ba5?s=96&d=mm&r=g","contentUrl":"https:\/\/secure.gravatar.com\/avatar\/b8c5d238e1fddd55d8a0064f1a534ba5?s=96&d=mm&r=g","caption":"Ryan Daws"},"description":"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and\/or Mastodon (@gadgetry@techhub.social)","sameAs":["https:\/\/twitter.com\/gadget_ry","https:\/\/x.com\/Gadget_Ry"],"url":"https:\/\/www.artificialintelligence-news.com\/news\/author\/ryan\/"}]}},"authors":[{"term_id":2401,"user_id":1570,"is_guest":0,"slug":"ryan","display_name":"Ryan Daws","avatar_url":{"url":"https:\/\/secure.gravatar.com\/avatar\/?s=96&d=mm&r=g","url2x":"https:\/\/secure.gravatar.com\/avatar\/?s=96&d=mm&r=g2x"},"user_url":"https:\/\/twitter.com\/gadget_ry","last_name":"Daws","first_name":"Ryan","job_title":"Senior Editor","description":"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and\/or Mastodon (@gadgetry@techhub.social)"}],"_links":{"self":[{"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/posts\/15062","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/users\/1570"}],"replies":[{"embeddable":true,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/comments?post=15062"}],"version-history":[{"count":0,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/posts\/15062\/revisions"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/media\/15064"}],"wp:attachment":[{"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/media?parent=15062"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/categories?post=15062"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/tags?post=15062"},{"taxonomy":"author","embeddable":true,"href":"https:\/\/www.artificialintelligence-news.com\/wp-json\/wp\/v2\/ppma_author?post=15062"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}