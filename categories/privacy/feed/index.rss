<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>AI Privacy News | AI Privacy Issues &amp; Solutions | AI News</title>
	<atom:link href="https://www.artificialintelligence-news.com/categories/privacy/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.artificialintelligence-news.com/categories/privacy/</link>
	<description>Artificial Intelligence News</description>
	<lastBuildDate>Thu, 19 Dec 2024 16:21:20 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url>
	<title>AI Privacy News | AI Privacy Issues &amp; Solutions | AI News</title>
	<link>https://www.artificialintelligence-news.com/categories/privacy/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>AI governance: Analysing emerging global regulations</title>
		<link>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=ai-governance-analysing-emerging-global-regulations</link>
					<comments>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Thu, 19 Dec 2024 16:21:18 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ai act]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[China]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[eu]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[framework]]></category>
		<category><![CDATA[governance]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Legislation]]></category>
		<category><![CDATA[privacy]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[risks]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[usa]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16742</guid>

					<description><![CDATA[<p>Governments are scrambling to establish regulations to govern AI, citing numerous concerns over data privacy, bias, safety, and more. AI News caught up with Nerijus Šveistys, Senior Legal Counsel at Oxylabs, to understand the state of play when it comes to AI regulation and its potential implications for industries, businesses, and innovation. “The boom of<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/" title="ReadAI governance: Analysing emerging global regulations">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/">AI governance: Analysing emerging global regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Governments are scrambling to establish regulations to govern AI, citing numerous concerns over data privacy, bias, safety, and more.</p>


<div class="wp-block-image">
<figure class="alignright size-full is-resized"><img fetchpriority="high" decoding="async" width="800" height="800" src="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs.jpeg" alt="" class="wp-image-16743" style="width:174px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs.jpeg 800w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-300x300.jpeg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-150x150.jpeg 150w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-768x768.jpeg 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-125x125.jpeg 125w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-200x200.jpeg 200w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-285x285.jpeg 285w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-250x250.jpeg 250w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-100x100.jpeg 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-60x60.jpeg 60w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-400x400.jpeg 400w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-600x600.jpeg 600w" sizes="(max-width: 800px) 100vw, 800px" /></figure></div>


<p>AI News caught up with Nerijus Šveistys, Senior Legal Counsel at <a href="https://oxylabs.io/">Oxylabs</a>, to understand the state of play when it comes to AI regulation and its potential implications for industries, businesses, and innovation.</p>



<p>“The boom of the last few years appears to have sparked a push to establish regulatory frameworks for AI governance,” explains Šveistys.</p>



<p>“This is a natural development, as the rise of AI seems to pose issues in data privacy and protection, bias and discrimination, safety, intellectual property, and other legal areas, as well as ethics that need to be addressed.”</p>



<h3 class="wp-block-heading">Regions diverge in regulatory strategy</h3>



<p>The European Union’s <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">AI Act</a> has, unsurprisingly, positioned the region with a strict, centralised approach. The regulation, which came into force this year, is set to be fully effective by 2026.</p>



<p>Šveistys pointed out that the EU has acted relatively swiftly compared to other jurisdictions: “The main difference we can see is the comparative quickness with which the EU has released a uniform regulation to govern the use of all types of AI.”</p>



<p>Meanwhile, other regions have opted for more piecemeal approaches. China, for instance, has been implementing regulations specific to certain AI technologies in a phased-out manner. According to Šveistys, China began regulating AI models as early as 2021.</p>



<p>“In 2021, they introduced regulation on recommendation algorithms, which [had] increased their capabilities in digital advertising. It was followed by regulations <a href="https://www.artificialintelligence-news.com/news/chinas-deepfake-laws-come-into-effect-today/">on deep synthesis models</a> or, in common terms, deepfakes and content generation in 2022,” he said.</p>



<p>“Then, in 2023, regulation on generative AI models was introduced as these models were making a splash in commercial usage.”</p>



<p>The US, in contrast, remains relatively uncoordinated in its approach. Federal-level regulations are yet to be enacted, with efforts mostly emerging at the state level.</p>



<p>“There are proposed regulations at the state level, such as the so-called California AI Act, but even if they come into power, it may still take some time before they do,” Šveistys noted.</p>



<p>This delay in implementing unified AI regulations in the US has raised questions about the extent to which business pushback may be contributing to the slow rollout. Šveistys said that while lobbyist pressure is a known factor, it’s not the only potential reason.</p>



<p>“There was <a href="https://www.artificialintelligence-news.com/news/tech-industry-giants-urge-eu-streamline-ai-regulations/">pushback to the EU AI Act</a>, too, which was nevertheless introduced. Thus, it is not clear whether the delay in the US is only due to lobbyism or other obstacles in the legislation enactment process,” explains Šveistys.</p>



<p>“It might also be because some still see AI as a futuristic concern, not fully appreciating the extent to which it is already a legal issue of today.”</p>



<h3 class="wp-block-heading">Balancing innovation and safety</h3>



<p>Differentiated regulatory approaches could affect the pace of innovation and business competitiveness across regions.</p>



<p>Europe’s regulatory framework, though more stringent, aims to ensure consumer protection and ethical adherence—something that less-regulated environments may lack.</p>



<p>“More rigid regulatory frameworks may impose compliance costs for businesses in the AI field and stifle competitiveness and innovation. On the other hand, they bring the benefits of protecting consumers and adhering to certain ethical norms,” comments Šveistys.</p>



<p>This trade-off is especially pronounced in AI-related sectors such as targeted advertising, where algorithmic bias is increasingly scrutinised.</p>



<p>AI governance often extends beyond laws that specifically target AI, incorporating related legal areas like those governing data collection and privacy. For example, the EU AI Act also regulates the use of AI in physical devices, such as elevators.</p>



<p>&#8220;Additionally, all businesses that collect data for advertisement are potentially affected as AI regulation can also cover algorithmic bias in targeted advertising,&#8221; emphasises Šveistys.</p>



<h3 class="wp-block-heading">Impact on related industries</h3>



<p>One industry that is deeply intertwined with AI developments is web scraping. Typically used for collecting publicly available data, web scraping is undergoing an AI-driven evolution.</p>



<p>&#8220;From data collection, validation, analysis, or overcoming anti-scraping measures, there is a lot of potential for AI to massively improve the efficiency, accuracy, and adaptability of web scraping operations,&#8221; said Šveistys.&nbsp;</p>



<p>However, as AI regulation and related laws tighten, web scraping companies will face greater scrutiny.</p>



<p>“AI regulations may also bring the spotlight on certain areas of law that were always very relevant to the web scraping industry, such as privacy or copyright laws,” Šveistys added.</p>



<p>“At the end of the day, scraping content protected by such laws without proper authorisation could always lead to legal issues, and now so can using AI this way.”</p>



<h3 class="wp-block-heading">Copyright battles and legal precedents</h3>



<p>The implications of AI regulation are also playing out on a broader legal stage, particularly in cases involving generative AI tools.</p>



<p>High-profile <a href="https://www.artificialintelligence-news.com/news/openai-and-microsoft-lawsuit-github-copilot/">lawsuits</a> have been launched against AI giants like OpenAI and its primary backer, Microsoft, by authors, artists, and musicians who claim their copyrighted materials were used to train AI systems without proper permission.</p>



<p>“These cases are pivotal in determining the legal boundaries of using copyrighted material for AI development and establishing legal precedents for protecting intellectual property in the digital age,” said Šveistys.</p>



<p>While these lawsuits could take years to resolve, their outcomes may fundamentally shape the future of AI development. So, what can businesses do now as the regulatory and legal landscape continues to evolve?</p>



<p>“Speaking about the specific cases of using copyrighted material for AI training, businesses should approach this the same way as any web-scraping activity – that is, evaluate the specific data they wish to collect with the help of a legal expert in the field,” recommends Šveistys.</p>



<p>“It is important to recognise that the AI legal landscape is very new and rapidly evolving, with not many precedents in place to refer to as of yet. Hence, continuous monitoring and adaptation of your AI usage are crucial.”</p>



<p>Just this week, the UK Government made headlines with its announcement of a consultation on the use of copyrighted material for training AI models. Under the proposals, tech firms could be permitted to use copyrighted material unless owners have specifically opted out.</p>



<p>Despite the diversity of approaches globally, the AI regulatory push marks a significant moment for technological governance. Whether through the EU’s comprehensive model, China’s step-by-step strategy, or narrower, state-level initiatives like in the US, businesses worldwide must navigate a complex, evolving framework.</p>



<p>The challenge ahead will be striking the right balance between fostering innovation and mitigating risks, ensuring that AI remains a force for good while avoiding potential harms.</p>



<p><em>(Photo by <a href="https://unsplash.com/@nathangbingle?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Nathan Bingle</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:844px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/">AI governance: Analysing emerging global regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Machine unlearning: Researchers make AI models ‘forget’ data</title>
		<link>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=machine-unlearning-researchers-ai-models-forget-data</link>
					<comments>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Tue, 10 Dec 2024 17:18:26 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[privacy]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16680</guid>

					<description><![CDATA[<p>Researchers from the Tokyo University of Science (TUS) have developed a method to enable large-scale AI models to selectively &#8220;forget&#8221; specific classes of data. Progress in AI has provided tools capable of revolutionising various domains, from healthcare to autonomous driving. However, as technology advances, so do its complexities and ethical considerations.&#160; The paradigm of large-scale<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/" title="ReadMachine unlearning: Researchers make AI models ‘forget’ data">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/">Machine unlearning: Researchers make AI models ‘forget’ data</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Researchers from the <a href="https://www.tus.ac.jp/en/">Tokyo University of Science</a> (TUS) have developed a method to enable large-scale AI models to selectively &#8220;forget&#8221; specific classes of data.</p>



<p>Progress in AI has provided tools capable of revolutionising various domains, from healthcare to autonomous driving. However, as technology advances, so do its complexities and ethical considerations.&nbsp;</p>



<p>The paradigm of large-scale pre-trained AI systems, such as OpenAI’s ChatGPT and <a href="https://openai.com/index/clip/">CLIP</a> (Contrastive Language–Image Pre-training), has reshaped expectations for machines. These highly generalist models, capable of handling a vast array of tasks with consistent precision, have seen widespread adoption for both professional and personal use.&nbsp;&nbsp;</p>



<p>However, such versatility comes at a hefty price. Training and running these models demands prodigious amounts of energy and time, raising sustainability concerns, as well as requiring cutting-edge hardware significantly more expensive than standard computers. Compounding these issues is that generalist tendencies may hinder the efficiency of AI models when applied to specific tasks.&nbsp;&nbsp;</p>



<p>For instance, “in practical applications, the classification of all kinds of object classes is rarely required,” explains Associate Professor Go Irie, who led the research. “For example, in an autonomous driving system, it would be sufficient to recognise limited classes of objects such as cars, pedestrians, and traffic signs.</p>



<p>“We would not need to recognise food, furniture, or animal species. Retaining classes that do not need to be recognised may decrease overall classification accuracy, as well as cause operational disadvantages such as the waste of computational resources and the risk of information leakage.”&nbsp;&nbsp;</p>



<p>A potential solution lies in training models to “forget” redundant or unnecessary information—streamlining their processes to focus solely on what is required. While some existing methods already cater to this need, they tend to assume a “white-box” approach where users have access to a model’s internal architecture and parameters. Oftentimes, however, users get no such visibility.&nbsp;&nbsp;</p>



<p>“Black-box” AI systems, more common due to commercial and ethical restrictions, conceal their inner mechanisms, rendering traditional forgetting techniques impractical. To address this gap, the research team turned to derivative-free optimisation—an approach that sidesteps reliance on the inaccessible internal workings of a model.&nbsp;&nbsp;</p>



<h3 class="wp-block-heading">Advancing through forgetting</h3>



<p>The study, set to be presented at the Neural Information Processing Systems (NeurIPS) conference in 2024, introduces a methodology dubbed “black-box forgetting.”</p>



<p>The process modifies the input prompts (text instructions fed to models) in iterative rounds to make the AI progressively &#8220;forget&#8221; certain classes. Associate Professor Irie collaborated on the work with co-authors Yusuke Kuwana and Yuta Goto (both from TUS), alongside Dr Takashi Shibata from <a href="https://www.nec.com/">NEC Corporation</a>.&nbsp;&nbsp;</p>



<p>For their experiments, the researchers targeted CLIP, a vision-language model with image classification abilities. The method they developed is built upon the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), an evolutionary algorithm designed to optimise solutions step-by-step. In this study, CMA-ES was harnessed to evaluate and hone prompts provided to CLIP, ultimately suppressing its ability to classify specific image categories.</p>



<p>As the project progressed, challenges arose. Existing optimisation techniques struggled to scale up for larger volumes of targeted categories, leading the team to devise a novel parametrisation strategy known as &#8220;latent context sharing.&#8221;&nbsp;&nbsp;</p>



<p>This approach breaks latent context – a representation of information generated by prompts – into smaller, more manageable pieces. By allocating certain elements to a single token (word or character) while reusing others across multiple tokens, they dramatically reduced the problem&#8217;s complexity. Crucially, this made the process computationally tractable even for extensive forgetting applications.&nbsp;&nbsp;</p>



<p>Through benchmark tests on multiple image classification datasets, the researchers validated the efficacy of black-box forgetting—achieving the goal of making CLIP &#8220;forget&#8221; approximately 40% of target classes without direct access to the AI model&#8217;s internal architecture.</p>



<p>This research marks the first successful attempt to induce selective forgetting in a black-box vision-language model, demonstrating promising results.&nbsp;&nbsp;</p>



<h3 class="wp-block-heading">Benefits of helping AI models forget data</h3>



<p>Beyond its technical ingenuity, this innovation holds significant potential for real-world applications where task-specific precision is paramount.</p>



<p>Simplifying models for specialised tasks could make them faster, more resource-efficient, and capable of running on less powerful devices—hastening the adoption of AI in areas previously deemed unfeasible.&nbsp;&nbsp;</p>



<p>Another key use lies in image generation, where forgetting entire categories of visual context could prevent models from inadvertently creating undesirable or harmful content, be it offensive material or misinformation.&nbsp;&nbsp;</p>



<p>Perhaps most importantly, this method addresses one of AI’s greatest ethical quandaries: <a href="https://www.artificialintelligence-news.com/categories/privacy/">privacy</a>.</p>



<p>AI models, particularly large-scale ones, are often trained on massive datasets that may inadvertently contain sensitive or outdated information. Requests to remove such data—especially in light of laws advocating for the “Right to be Forgotten”—pose significant challenges.</p>



<p>Retraining entire models to exclude problematic data is costly and time-intensive, yet the risks of leaving it unaddressed can have far-reaching consequences.</p>



<p>“Retraining a large-scale model consumes enormous amounts of energy,” notes Associate Professor Irie. “‘Selective forgetting,’ or so-called machine unlearning, may provide an efficient solution to this problem.”&nbsp;&nbsp;</p>



<p>These privacy-focused applications are especially relevant in high-stakes industries like <a href="https://www.artificialintelligence-news.com/categories/ai-industries/healthcare/">healthcare</a> and <a href="https://www.artificialintelligence-news.com/news/large-language-models-could-revolutionsise-the-finance-sector-within-two-years/">finance</a>, where sensitive data is central to operations.&nbsp;&nbsp;</p>



<p>As the global race to advance AI accelerates, the Tokyo University of Science’s black-box forgetting approach charts an important path forward—not only by making the technology more adaptable and efficient but also by adding significant safeguards for users.&nbsp;&nbsp;</p>



<p>While the potential for misuse remains, methods like selective forgetting demonstrate that researchers are proactively addressing both ethical and practical challenges.&nbsp;&nbsp;</p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/why-qwq-32b-preview-is-the-reasoning-ai-to-watch/"><strong>Why QwQ-32B-Preview is the reasoning AI to watch</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:769px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/">Machine unlearning: Researchers make AI models ‘forget’ data</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>EU introduces draft regulatory guidance for AI models</title>
		<link>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=eu-introduces-draft-regulatory-guidance-for-ai-models</link>
					<comments>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 15 Nov 2024 14:52:05 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ai act]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[eu]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[european union]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[guidance]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Politics]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16496</guid>

					<description><![CDATA[<p>The release of the &#8220;First Draft General-Purpose AI Code of Practice&#8221; marks the EU&#8217;s effort to create comprehensive regulatory guidance for general-purpose AI models. The development of this draft has been a collaborative effort, involving input from diverse sectors including industry, academia, and civil society. The initiative was led by four specialised Working Groups, each<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/" title="ReadEU introduces draft regulatory guidance for AI models">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/">EU introduces draft regulatory guidance for AI models</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The <a href="https://digital-strategy.ec.europa.eu/en/library/first-draft-general-purpose-ai-code-practice-published-written-independent-experts">release</a> of the &#8220;First Draft General-Purpose AI Code of Practice&#8221; marks the EU&#8217;s effort to create comprehensive regulatory guidance for general-purpose AI models.</p>



<p>The development of this draft has been a collaborative effort, involving input from diverse sectors including industry, academia, and civil society. The initiative was led by four specialised Working Groups, each addressing specific aspects of AI governance and risk mitigation:</p>



<ul class="wp-block-list">
<li>Working Group 1: Transparency and copyright-related rules</li>



<li>Working Group 2: Risk identification and assessment for systemic risk</li>



<li>Working Group 3: Technical risk mitigation for systemic risk</li>



<li>Working Group 4: Governance risk mitigation for systemic risk</li>
</ul>



<p>The draft is aligned with existing laws such as the Charter of Fundamental Rights of the European Union. It takes into account international approaches, striving for proportionality to risks, and aims to be future-proof by contemplating rapid technological changes.</p>



<p>Key objectives outlined in the draft include:</p>



<ul class="wp-block-list">
<li>Clarifying compliance methods for providers of general-purpose AI models</li>



<li>Facilitating understanding across the AI value chain, ensuring seamless integration of AI models into downstream products</li>



<li>Ensuring compliance with Union law on copyrights, especially concerning the use of copyrighted material for model training</li>



<li>Continuously assessing and mitigating systemic risks associated with AI models</li>
</ul>



<h3 class="wp-block-heading">Recognising and mitigating systemic risks</h3>



<p>A core feature of the draft is its taxonomy of systemic risks, which includes types, natures, and sources of such risks. The document outlines various threats such as cyber offences, biological risks, loss of control over autonomous AI models, and large-scale disinformation. By acknowledging the continuously evolving nature of AI technology, the draft recognises that this taxonomy will need updates to remain relevant.</p>



<p>As AI models with systemic risks become more common, the draft emphasises the need for robust safety and security frameworks (SSFs). It proposes a hierarchy of measures, sub-measures, and key performance indicators (KPIs) to ensure appropriate risk identification, analysis, and mitigation throughout a model&#8217;s lifecycle.</p>



<p>The draft suggests that providers establish processes to identify and report serious incidents associated with their AI models, offering detailed assessments and corrections as needed. It also encourages collaboration with independent experts for risk assessment, especially for models posing significant systemic risks.</p>



<h3 class="wp-block-heading">Taking a proactive stance to AI regulatory guidance</h3>



<p>The <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">EU AI Act</a>, which came into force on 1 August 2024, mandates that the final version of this Code be ready by 1 May 2025. This initiative underscores the EU&#8217;s proactive stance towards AI regulation, emphasising the need for AI safety, transparency, and accountability.</p>



<p>As the draft continues to evolve, the working groups invite stakeholders to participate actively in refining the document. Their collaborative input will shape a regulatory framework aimed at safeguarding innovation while protecting society from the potential pitfalls of AI technology.</p>



<p>While still in draft form, the EU&#8217;s Code of Practice for general-purpose AI models could set a benchmark for responsible AI development and deployment globally. By addressing key issues such as transparency, risk management, and copyright compliance, the Code aims to create a regulatory environment that fosters innovation, upholds fundamental rights, and ensures a high level of consumer protection.</p>



<p><em>This draft is open for written feedback until 28 November 2024.&nbsp;</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:2239px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/">EU introduces draft regulatory guidance for AI models</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>AI hallucinations gone wrong as Alaska uses fake stats in policy</title>
		<link>https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy</link>
					<comments>https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/#respond</comments>
		
		<dc:creator><![CDATA[Muhammad Zulhusni]]></dc:creator>
		<pubDate>Tue, 05 Nov 2024 16:12:42 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Chatbots]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[policy]]></category>
		<category><![CDATA[research]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16432</guid>

					<description><![CDATA[<p>The combination of artificial intelligence and policymaking can occasionally have unforeseen repercussions, as seen recently in Alaska. In an unusual turn of events, Alaska legislators reportedly used AI-generated citations that were inaccurate to justify a proposed policy banning cellphones in schools. As reported by /The Alaska Beacon/, Alaska’s Department of Education and Early Development (DEED)<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/" title="ReadAI hallucinations gone wrong as Alaska uses fake stats in policy">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/">AI hallucinations gone wrong as Alaska uses fake stats in policy</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The combination of artificial intelligence and policymaking can occasionally have unforeseen repercussions, as seen recently in Alaska.</p>



<p>In an unusual turn of events, Alaska legislators reportedly used AI-generated citations that were inaccurate to justify a proposed policy banning cellphones in schools. As reported by /The Alaska Beacon/, Alaska’s Department of Education and Early Development (DEED) presented a policy draft containing references to academic studies that simply did not exist.</p>



<p>The situation arose when Alaska’s Education Commissioner, Deena Bishop, used generative AI to draft the cellphone policy. The document produced by the AI included supposed scholarly references that were neither verified nor accurate, yet the document did not disclose the use of AI in its preparation. Some of the AI-generated content reached the Alaska State Board of Education and Early Development before it could be reviewed, potentially influencing board discussions.</p>



<p>Commissioner Bishop later claimed that AI was used only to “create citations” for an initial draft and asserted that she corrected the errors before the meeting by sending updated citations to board members. However, AI “hallucinations”—fabricated information generated when AI attempts to create plausible yet unverified content—were still present in the final document that was voted on by the board.</p>



<p>The final resolution, published on DEED’s website, directs the department to establish a model policy for cellphone restrictions in schools. Unfortunately, the document included six citations, four of which seemed to be from respected scientific journals. However, the references were entirely made up, with URLs that led to unrelated content. The incident shows the risks of using AI-generated data without proper human verification, especially when making policy rulings.</p>



<p>Alaska’s case is not one of a kind. AI hallucinations are increasingly common in a variety of professional sectors. For example, some legal professionals have faced consequences for using AI-generated, fictitious case citations in court. Similarly, academic papers created using AI have included distorted data and fake sources, presenting serious credibility concerns. When left unchecked, generative AI algorithms, which are meant to produce content based on patterns rather than factual accuracy, can easily produce misleading citations.</p>



<p>The reliance on AI-generated data in policymaking, particularly in education, carries significant risks. When policies are developed based on fabricated information, they may misallocate resources and potentially harm students. For instance, a policy restricting cellphone use based on fabricated data may divert attention from more effective, evidence-based interventions that could genuinely benefit students.</p>



<p>Furthermore, using unverified AI data can erode public trust in both the policymaking process and AI technology itself. Such incidents underscore the importance of fact-checking, transparency, and caution when using AI in sensitive decision-making areas, especially in education, where impact on students can be profound.</p>



<p>Alaska officials attempted to downplay the situation, referring to the fabricated citations as “placeholders” intended for later correction. However, the document with the “placeholders” was still presented to the board and used as the basis for a vote, underscoring the need for rigorous oversight when using AI.</p>



<p><em>(Photo by <a href="https://unsplash.com/@hartonocreativestudio?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Hartono Creative Studio</a>)</em></p>



<p><strong>See also: <a target="_blank" href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/" rel="noreferrer noopener">Anthropic urges AI regulation to avoid catastrophes</a></strong></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/">AI hallucinations gone wrong as Alaska uses fake stats in policy</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Industry leaders back open-source AI definition</title>
		<link>https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=industry-leaders-back-open-source-ai-definition</link>
					<comments>https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Tue, 29 Oct 2024 14:36:15 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Companies]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[all things open]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[open source]]></category>
		<category><![CDATA[open source initiative]]></category>
		<category><![CDATA[open-source]]></category>
		<category><![CDATA[osaid]]></category>
		<category><![CDATA[osi]]></category>
		<category><![CDATA[training]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16411</guid>

					<description><![CDATA[<p>The Open Source Initiative (OSI) has unveiled a definition framework to evaluate whether AI systems can be classified as open-source. The announcement of the first Open Source AI Definition (OSAID) was made at All Things Open and marks the culmination of a comprehensive global effort spanning multiple years of research, international workshops, and a year-long<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/" title="ReadIndustry leaders back open-source AI definition">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/">Industry leaders back open-source AI definition</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The <a href="https://opensource.org/">Open Source Initiative</a> (OSI) has unveiled a definition framework to evaluate whether AI systems can be classified as open-source.</p>



<p>The announcement of the first Open Source AI Definition (OSAID) was made at <a href="https://allthingsopen.org/">All Things Open</a> and marks the culmination of a comprehensive global effort spanning multiple years of research, international workshops, and a year-long community design process.</p>



<p>The OSI – widely recognised as the definitive authority on open-source definitions by individuals, organisations, and government bodies worldwide – developed the framework through extensive collaboration with industry stakeholders. This framework defines what open-source AI means, insisting that the same open-source requirements apply whether to a fully functional AI system, a model, weights and parameters, or other structural elements.</p>



<p>An open-source AI system must be made available under terms that grant four essential freedoms:</p>



<ul class="wp-block-list">
<li><strong>Use the system for any purpose</strong> and without having to ask for permission.</li>



<li><strong>Study how the system works</strong> and inspect its components.</li>



<li><strong>Modify the system</strong> for any purpose, including to change its output.</li>



<li><strong>Share the system</strong> for others to use with or without modifications, for any purpose.</li>
</ul>



<p>These freedoms apply both to a fully functional system and to discrete elements of a system. A precondition to exercising these freedoms is having access to the preferred form to make modifications to the system, which includes detailed data information, complete source code, and model parameters.</p>



<p>&#8220;The co-design process that led to version 1.0 of the Open Source AI Definition was well-developed, thorough, inclusive, and fair,&#8221; said Carlo Piana, OSI board chair. &#8220;The board is confident that the process has resulted in a definition that meets the standards of open-source as defined in the open-source definition and the four essential freedoms.&#8221;</p>



<p>One of the framework&#8217;s most significant requirements is the mandate for open-source models to provide sufficient information about <a href="https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/">their training data</a>, ensuring that &#8220;a skilled person can recreate a substantially equivalent system using the same or similar data,&#8221; according to Ayah Bdeir, who leads AI strategy at <a href="https://www.mozilla.org/en-GB/">Mozilla</a>.</p>



<p>Bdeir acknowledged that whilst this approach might not be perfect, it represents a practical compromise between ideological purity and real-world implementation. She suggested that demanding an unrealistically high standard could prove counterproductive to the initiative&#8217;s goals.</p>



<p>The <a href="https://www.digitalpublicgoods.net/implement">Digital Public Goods Alliance</a> (DPGA) has expressed support for the OSI&#8217;s leadership in defining open-source AI. Liv Marte Nordhaug, CEO of the DPGA secretariat, confirmed that her organisation will incorporate this foundational work into updates to their Digital Public Goods Standard for AI applications.</p>



<p><a href="https://www.eleuther.ai/">EleutherAI Institute</a>, known for its non-profit work in AI development, has also endorsed the definition.</p>



<p>&#8220;The Open Source AI Definition is a necessary step towards promoting the benefits of open-source principles in the field of AI,&#8221; stated Stella Biderman, Executive Director of the EleutherAI Institute. &#8220;We believe that this definition supports the needs of independent machine learning researchers and promotes greater transparency among the largest AI developers.&#8221;</p>



<p>The definition highlights the importance of including data information and code when sharing open-source models and weights. These requirements ensure transparency and the ability to modify the AI system.</p>



<p>OSI Executive Director Stefano Maffulli acknowledged the challenges faced during the development process, noting that despite occasional heated exchanges and differing opinions, the final result aligned with the project&#8217;s initial objectives.</p>



<p>&#8220;This is a starting point for a continued effort to engage with the communities to improve the definition over time,&#8221; he stated.</p>



<p>The OSAID does not require a specific legal mechanism for assuring that model parameters are freely available to all, though it may involve licences or legal instruments. This aspect is expected to become clearer over time as <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">the legal system</a> addresses these open-source AI systems.</p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/"><strong>President Biden issues first National Security Memorandum on AI</strong></a></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/">Industry leaders back open-source AI definition</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Intern allegedly sabotages ByteDance AI project, leading to dismissal</title>
		<link>https://www.artificialintelligence-news.com/news/intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal</link>
					<comments>https://www.artificialintelligence-news.com/news/intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal/#respond</comments>
		
		<dc:creator><![CDATA[Muhammad Zulhusni]]></dc:creator>
		<pubDate>Fri, 25 Oct 2024 06:31:40 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[tiktok]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16387</guid>

					<description><![CDATA[<p>ByteDance, the creator of TikTok, recently experienced a security breach involving an intern who allegedly sabotaged AI model training. The incident, reported on WeChat, raised concerns about the company&#8217;s security protocols in its AI department. In response, ByteDance clarified that while the intern disrupted AI commercialisation efforts, no online operations or commercial projects were affected.<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal/" title="ReadIntern allegedly sabotages ByteDance AI project, leading to dismissal">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal/">Intern allegedly sabotages ByteDance AI project, leading to dismissal</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>ByteDance, the creator of TikTok, recently experienced a security breach involving an intern who allegedly sabotaged AI model training. The incident, reported on WeChat, raised concerns about the company&#8217;s security protocols in its AI department.</p>



<p>In response, <a href="https://www.toutiao.com/w/1813324433807370/?app=news_article&amp;timestamp=1729482540&amp;use_new_style=1&amp;share_token=08E369A6-498A-49A0-AE65-0A3AB19A5EFE&amp;tt_from=weixin&amp;utm_source=weixin&amp;utm_medium=toutiao_ios&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;source=m_redirect&amp;wid=1729817755484" target="_blank" rel="noreferrer noopener">ByteDance clarified</a> that while the intern disrupted AI commercialisation efforts, no online operations or commercial projects were affected. According to the company, rumours that over 8,000 GPU cards were affected and that the breach resulted in millions of dollars in losses are taken out of proportion.</p>



<p>The real issue here goes beyond one rogue intern—it highlights the need for stricter security measures in tech companies, especially when interns are entrusted with key responsibilities. Even minor mistakes in high-pressure environments can have serious consequences.</p>



<p>On investigating, ByteDance found that the intern, a doctoral student, was part of the commercialisation tech team, not the AI Lab. The individual was dismissed in August.</p>



<p>According to the local media outlet Jiemian, the intern became frustrated with resource allocation and retaliated by exploiting a vulnerability in the AI development platform Hugging Face. This led to disruptions in model training, though ByteDance&#8217;s commercial Doubao model was not affected.</p>



<p>Despite the disruption, ByteDance&#8217;s automated machine learning (AML) team initially struggled to identify the cause. Fortunately, the attack only impacted internal models, minimising broader damage.</p>



<p>As context, China&#8217;s AI market, estimated to be worth $250 billion in 2023, is rapidly increasing in size, with industry leaders such as Baidu AI Cloud, SenseRobot, and Zhipu AI driving innovation. However, incidents like this one pose a huge risk to the commercialisation of AI technology, as model accuracy and reliability are directly related to business success.</p>



<p>The situation also raises questions about intern management in tech companies. Interns often play crucial roles in fast-paced environments, but without proper oversight and security protocols, their roles can pose risks. Companies must ensure that interns receive adequate training and supervision to prevent unintentional or malicious actions that could disrupt operations.</p>



<p><strong>Implications for AI commercialisation</strong></p>



<p>The security breach highlights the possible risks to AI commercialisation. A disruption in AI model training, such as this one, can cause delays in product releases, loss of client trust, and even financial losses. For a company like ByteDance, where AI drives core functionalities, these kinds of incidents are particularly damaging.</p>



<p>The issue emphasises the importance of ethical AI development and business responsibility. Companies must not only develop cutting-edge AI technology, but also ensure their security and operate responsible management. Transparency and accountability are critical for retaining trust in an era when AI plays an important role in business operations.</p>



<p><em>(Photo by <a href="https://unsplash.com/@jupp?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Jonathan Kemper</a>)</em></p>



<p><strong>See also: <a href="https://www.artificialintelligence-news.com/news/microsoft-major-ai-client-tiktok-spends-20-million-monthly/">Microsoft gains major AI client as TikTok spends $20 million monthly</a></strong></p>



<figure class="wp-block-image"><a href="https://www.ai-expo.net/"><img decoding="async" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="This image has an empty alt attribute; its file name is ai-expo-world-728x-90-01.png"/></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal/">Intern allegedly sabotages ByteDance AI project, leading to dismissal</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/intern-allegedly-sabotages-bytedance-ai-project-leading-to-dismissal/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Penguin Random House protects its books from AI training use</title>
		<link>https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=penguin-random-house-protects-its-books-from-ai-training-use</link>
					<comments>https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/#respond</comments>
		
		<dc:creator><![CDATA[Muhammad Zulhusni]]></dc:creator>
		<pubDate>Tue, 22 Oct 2024 18:36:29 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[generative ai]]></category>
		<category><![CDATA[law]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16353</guid>

					<description><![CDATA[<p>Penguin Random House (PRH) has taken a significant step in response to rising concerns about the use of intellectual property to train AI systems. The publisher has introduced a new statement to the copyright pages of both new and reprinted books, stating, &#8220;No part of this book may be used or reproduced in any manner<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/" title="ReadPenguin Random House protects its books from AI training use">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/">Penguin Random House protects its books from AI training use</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Penguin Random House (PRH) has taken a significant step in response to rising concerns about the use of intellectual property to train AI systems.</p>



<p>The publisher has introduced <a target="_blank" href="https://www.thebookseller.com/news/penguin-random-house-underscores-copyright-protection-in-ai-rebuff" rel="noreferrer noopener">a new statement</a> to the copyright pages of both new and reprinted books, stating, &#8220;No part of this book may be used or reproduced in any manner for the purpose of training artificial intelligence technologies or systems.&#8221; This change is supplemented by a section that excludes PRH&#8217;s works from the European Union&#8217;s text and data mining exception, in accordance with applicable copyright laws.</p>



<p>As one of the first major publishers to address the issue of AI training explicitly, PRH is responding to the broader debate about how tech companies use copyrighted content to train large language models (LLMs), like those used in chatbots and other AI tools. Publishers have become increasingly concerned about the possible misuse of their intellectual property in recent years, especially after reports arose that copyrighted books were utilised by AI firms to enhance these technologies.</p>



<p>PRH&#8217;s move to amend its copyright page is an attempt to protect its content ahead of time, even though such comments have no bearing on the legal framework of copyright. The clauses work similarly to a &#8220;robots.txt&#8221; file, which websites employ to request that their content not be scraped by bots or AI systems. While these notices indicate the publisher&#8217;s intent, they are not legally binding, and existing copyright protections apply in the absence of such disclaimers.</p>



<p>PRH&#8217;s move also emphasises the ongoing tension between content creators and the AI industry, as more authors, publishers, and other creatives ask for stronger protections. The Authors&#8217; Licensing and Collecting Society (ALCS) has been outspoken in its support for PRH&#8217;s actions. ALCS CEO Barbara Hayes expressed approval of the updated copyright language, emphasising the need for publishers to protect their works from unauthorised use in AI training.</p>



<p>However, some contend that simply changing copyright pages may not be enough. The Society of Authors (SoA) applauds PRH&#8217;s efforts, but believes more needs to be done to guarantee that authors&#8217; rights are properly protected. SoA CEO Anna Ganley has called on publishers to go beyond these statements and incorporate explicit protections in author contracts, making sure that writers are informed before their work is used in AI-related initiatives.</p>



<p>As AI advances, the debate over its usage of copyrighted content remains far from over. PRH&#8217;s action could herald a larger shift in the publishing sector, but how other publishers and the legal system react remains to be seen.</p>



<p><em>(Image by <a href="https://pixabay.com/users/stocksnap-894430/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2599241">StockSnap</a>)</em></p>



<p><strong>See also: <a target="_blank" href="https://www.artificialintelligence-news.com/news/ai-governance-gap-95-of-firms-havent-frameworks/" rel="noreferrer noopener">AI governance gap: 95% of firms haven&#8217;t implemented frameworks</a></strong></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/">Penguin Random House protects its books from AI training use</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Regulations to help or hinder: Cloudflare&#8217;s take</title>
		<link>https://www.artificialintelligence-news.com/news/regulations-to-help-or-hinder-cloudflares-take/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=regulations-to-help-or-hinder-cloudflares-take</link>
					<comments>https://www.artificialintelligence-news.com/news/regulations-to-help-or-hinder-cloudflares-take/#respond</comments>
		
		<dc:creator><![CDATA[Dashveenjit Kaur]]></dc:creator>
		<pubDate>Tue, 01 Oct 2024 11:19:32 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Companies]]></category>
		<category><![CDATA[Enterprise]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[cyber securitty]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16216</guid>

					<description><![CDATA[<p>As AI reshapes the digital landscape, tech companies find themselves in a high-stakes game of regulatory chess, with each move potentially changing the possibilities stemming from innovation. The game board is especially intricate for global infrastructure providers like Cloudflare, involving as it does cybersecurity, data privacy, and content moderation in a complex policy framework. “No<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/regulations-to-help-or-hinder-cloudflares-take/" title="ReadRegulations to help or hinder: Cloudflare&#8217;s take">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/regulations-to-help-or-hinder-cloudflares-take/">Regulations to help or hinder: Cloudflare&#8217;s take</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>As AI reshapes the digital landscape, tech companies find themselves in a high-stakes game of regulatory chess, with each move potentially changing the possibilities stemming from innovation. The game board is especially intricate for global infrastructure providers like Cloudflare, involving as it does cybersecurity, data privacy, and content moderation in a complex policy framework.</p>



<p>“No one wants to miss the boat,” says Alissa Starzak, the company’s deputy chief legal officer and global head of public policy, referring to the rush to regulate AI. Yet, she cautions the tension between urgent action and measured response that encapsulates the complex balancing act Cloudflare navigates daily.</p>



<p>In a recent interview with <em>Artificial Intelligence News</em>, Starzak revealed how the internet infrastructure giant is working to shape a regulatory framework that fosters innovation while safeguarding against emerging cyber threats.</p>



<h3 class="wp-block-heading"><a></a><strong>The AI regulatory conundrum: Speed vs.&nbsp;caution</strong><strong></strong></h3>



<p>Regulators worldwide face the question of how to mandate as AI technology advances. Urgency is muted by a significant fact: the main dimensions of potential AI are not fully understood yet. “No one really knows yet,” Starzak said, highlighting the challenge of crafting regulations for a technology with unknown scope.</p>



<p>A lack of knowledge has led to producing responsible AI development and deployment frameworks that are speculative. An example would be the AI risk framework set by the <a href="https://www.nist.gov">National Institute of Standards and Technology</a>&nbsp;(NIST), which Starzak said were meaningful steps towards the goal. Voluntary guidelines provide companies with a roadmap for creating AI risk assessment measures and encourage them to do so without <a href="https://techhq.com/2024/09/europes-tech-wake-up-call-draghis-plan-to-close-the-innovation-gap/">stifling innovation</a>.</p>



<h3 class="wp-block-heading"><a></a><strong>The tightrope of global regulatory harmonisation</strong><strong></strong></h3>



<p>Cloudflare is congnisant of the complexities of achieving regulatory harmony across different jurisdictions, particularly in data protection and privacy. Starzak used the EU’s General Data Protection Regulation (GDPR) to illustrate the benefits and challenges of sweeping regulatory frameworks.</p>



<p>It is noteworthy that GDPR has a significant role in consolidating privacy norms internationally. Starzak said that its real-life application does not always harmonise with the functioning of the internet. “It doesn’t actually feel like the way the internet necessarily works in practice,” she said, referring to restrictions on data transfers between jurisdictions.</p>



<p>This disconnect highlights a broader challenge: crafting regulations that protect consumers and national interests without impeding the global nature of the internet and digital commerce. Starzak emphasised the need for regulatory mechanisms that are “consistent across jurisdiction to jurisdiction, but enable information to travel.”</p>



<h3 class="wp-block-heading"><a></a><strong>The imperative of targeted, narrow actions</strong><strong></strong></h3>



<p>Starzak advocates for a more nuanced, targeted approach to cybersecurity measures and content moderation. Her philosophy is rooted in recognising that broad, sweeping actions often have unintended consequences that can harm the ecosystem they aim to protect.</p>



<p>In terms of cybersecurity, Starzak stressed the importance of proportionality. She drew a stark contrast between targeted actions, like removing a specific piece of content, and drastic measures, like complete internet shutdowns. “The narrower that you can go, the better off you’re going to be from an open internet standpoint,” she said.</p>



<p>The principle extends to content moderation as well. As Starzak describes, the approach by Cloudflare involves carefully distinguishing between different types of services and their impacts. By doing so, the company aims to make more precise, effective decisions that address specific issues without unnecessarily compromising the broader internet ecosystem.</p>



<h3 class="wp-block-heading"><a></a><strong>Balancing innovation and regulation in AI</strong><strong></strong></h3>



<p>The rapid advancement of AI technology presents a unique regulatory challenge. Starzak highlighted the risk of over-regulation stifling innovation and concentrating power in the hands of a few large players. “If you regulate it too much, you restrict the industry in a very significant way and make it really only available to a very small number of players,” she said.</p>



<p>Starzak advocates a regulatory approach that encourages responsible innovation while addressing potential harms. This includes promoting the development and adoption of AI risk assessment frameworks and encouraging industry self-regulation through model testing and ‘red teaming.’</p>



<h3 class="wp-block-heading"><strong>The path forward: collaboration and flexibility</strong><strong></strong></h3>



<p>Starzak emphasises the need for ongoing dialogue and flexibility in regulatory approaches to AI and cybersecurity. She highlighted the importance of industry, government, and civil society collaboration to develop effective, balanced regulations.</p>



<p>According to Starzak, the key is to focus on specific harms and consumer protection rather than broad, sweeping regulations. “You have to go in with a purpose,” she stated, urging regulators to understand and articulate the problems they’re trying to solve.</p>



<p>A targeted approach, combined with willingness to adapt as technologies evolve offers a path forward through the complex internet and AI regulation world. As Cloudflare continues to navigate this landscape, Starzak’s insights provide a roadmap for balancing innovation, security, and responsible governance.</p>



<p>As the tech industry and regulators grapple with the challenge of creating effective governance frameworks, Cloudflare’s approach emphasises targeted actions, global harmonisation efforts, and regulatory flexibility. It represents a thoughtful perspective in the dialogue between tech companies and policymakers.</p>



<p>The way forward likely involves collaborative efforts from various stakeholders, including industry leaders, government bodies, and civil society organisations. The focus remains on striking a balance between protecting users and fostering innovation. This goal requires ongoing adaptation and cooperation across the tech ecosystem.</p>



<p><strong>See</strong>&nbsp;<strong>also:</strong>&nbsp;<a href="https://www.artificialintelligence-news.com/news/balancing-innovation-trust-experts-assess-eu-ai-act/">Balancing innovation and trust: Experts assess the EU’s AI Act</a></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/regulations-to-help-or-hinder-cloudflares-take/">Regulations to help or hinder: Cloudflare&#8217;s take</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/regulations-to-help-or-hinder-cloudflares-take/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>SolarWinds: IT professionals want stronger AI regulation</title>
		<link>https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=solarwinds-it-professionals-stronger-ai-regulation</link>
					<comments>https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Tue, 17 Sep 2024 14:36:25 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[adoption]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[data]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Legislation]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[report]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[solarwinds]]></category>
		<category><![CDATA[study]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16093</guid>

					<description><![CDATA[<p>A new survey from SolarWinds has unveiled a resounding call for increased government oversight of AI, with 88% of IT professionals advocating for stronger regulation. The study, which polled nearly 700 IT experts, highlights security as the paramount concern. An overwhelming 72% of respondents emphasised the critical need for measures to secure infrastructure. Privacy follows<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/" title="ReadSolarWinds: IT professionals want stronger AI regulation">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/">SolarWinds: IT professionals want stronger AI regulation</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>A new survey from <a href="https://www.solarwinds.com/">SolarWinds</a> has unveiled a resounding call for increased government oversight of AI, with 88% of IT professionals advocating for stronger regulation.</p>



<p>The study, which polled nearly 700 IT experts, highlights <a href="https://www.artificialintelligence-news.com/news/psa-certified-ai-growth-outpacing-security-measures/">security</a> as the paramount concern. An overwhelming 72% of respondents emphasised the critical need for measures to secure infrastructure. <a href="https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/">Privacy</a> follows closely behind, with 64% of IT professionals urging for more robust rules to protect sensitive information.</p>



<p>Rob Johnson, VP and Global Head of Solutions Engineering at SolarWinds, commented: &#8220;It is understandable that IT leaders are approaching AI with caution. As technology rapidly evolves, it naturally presents challenges typical of any emerging innovation.</p>



<p>“Security and privacy remain at the forefront, with ongoing scrutiny by regulatory bodies. However, it is incumbent upon organisations to take proactive measures by enhancing data hygiene, enforcing robust AI ethics and assembling the right teams to lead these efforts. This proactive stance not only helps with compliance with evolving regulations but also maximises the potential of AI.”</p>



<p>The survey&#8217;s findings come at a pivotal moment, coinciding with the implementation of <a href="https://www.artificialintelligence-news.com/news/balancing-innovation-trust-experts-assess-eu-ai-act/">the EU&#8217;s AI Act</a>. In <a href="https://www.artificialintelligence-news.com/news/uk-signs-ai-safety-treaty-to-protect-human-rights-and-democracy/">the UK</a>, the new Labour government recently proposed its own AI legislation during the latest King&#8217;s speech, signalling a growing recognition of the need for regulatory frameworks. In the US, the California State Assembly passed <a href="https://www.artificialintelligence-news.com/categories/ai-legislation-government/">a controversial AI safety bill</a> last month.</p>



<p>Beyond security and privacy, the survey reveals a broader spectrum of concerns amongst IT professionals. A majority (55%) believe government intervention is crucial to stem the tide of <a href="https://www.artificialintelligence-news.com/news/ai-pioneers-turn-whistleblowers-demand-safeguards/">AI-generated misinformation</a>. Additionally, half of the respondents support regulations aimed at ensuring transparency and ethical practices in AI development.</p>



<h3 class="wp-block-heading">Challenges extend beyond AI regulation</h3>



<p>However, the challenges facing AI adoption extend beyond regulatory concerns. The survey uncovers a troubling lack of trust in data quality—a cornerstone of successful AI implementation.</p>



<p>Only 38% of respondents consider themselves &#8216;very trusting&#8217; of the data quality and training used in AI systems. This scepticism is not unfounded, as 40% of IT leaders who have encountered issues with AI attribute these problems to algorithmic errors stemming from insufficient or <a href="https://www.artificialintelligence-news.com/news/chatgpt-political-bias-highlighted-study/">biased</a> data.</p>



<p>Consequently, data quality emerges as the second most significant barrier to AI adoption (16%), trailing only behind security and privacy risks. This finding underscores the critical importance of robust, unbiased datasets in driving AI success.</p>



<p>“High-quality data is the cornerstone of accurate and reliable AI models, which in turn drive better decision-making and outcomes,” adds Johnson. “Trustworthy data builds confidence in AI among IT professionals, accelerating the broader adoption and integration of AI technologies.&#8221;</p>



<p>The survey also sheds light on widespread concerns about database readiness. Less than half (43%) of IT professionals express confidence in their company&#8217;s ability to meet the increasing data demands of AI. This lack of preparedness is further exacerbated by the perception that organisations are not moving swiftly enough to implement AI, with 46% of respondents citing ongoing data quality challenges as a contributing factor.</p>



<p>As AI continues to reshape the technological landscape, the findings of this SolarWinds survey serve as a clarion call for both stronger regulation and improved data practices. The message from IT professionals is clear: while AI holds immense promise, its successful integration hinges on addressing critical concerns around security, privacy, and data quality.</p>



<p><em>(Photo by <a href="https://unsplash.com/@kellysikkema?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Kelly Sikkema</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/whitepaper-dispels-fears-ai-induced-job-losses/"><strong>Whitepaper dispels fears of AI-induced job losses</strong></a></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/">SolarWinds: IT professionals want stronger AI regulation</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>X agrees to halt use of certain EU data for AI chatbot training</title>
		<link>https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=x-agrees-halt-use-certain-eu-data-ai-chatbot-training</link>
					<comments>https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/#respond</comments>
		
		<dc:creator><![CDATA[Muhammad Zulhusni]]></dc:creator>
		<pubDate>Wed, 14 Aug 2024 08:59:13 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Chatbots]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[chatbot]]></category>
		<category><![CDATA[data privacy]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=15718</guid>

					<description><![CDATA[<p>Recently, the European Union became the centre stage of a data privacy controversy related to the social media platform X. On August 8, an Irish court declared that X had agreed to suspend the use of all data belonging to European Union citizens, which had been gathered via the platform for the purpose of training<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/" title="ReadX agrees to halt use of certain EU data for AI chatbot training">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/">X agrees to halt use of certain EU data for AI chatbot training</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Recently, the European Union became the centre stage of a data privacy controversy related to the social media platform X.</p>



<p>On August 8, an Irish court declared that X had agreed to suspend the use of all data belonging to European Union citizens, which had been gathered via the platform for the purpose of training the company&#8217;s AI systems. As reported by <em><a href="https://economictimes.indiatimes.com/tech/artificial-intelligence/x-agrees-to-not-use-some-eu-user-data-to-train-ai-chatbot/articleshow/112392029.cms?from=mdr" target="_blank" rel="noreferrer noopener">The Economic Times</a></em>, this initiative was prompted by complaints from the Data Protection Commission (DPC) of Ireland, the leading EU regulator for many large US tech companies that have their main offices in Ireland under EU law.</p>



<p>Taking action, the DPC&#8217;s intervention comes amid intensified scrutiny of AI development practices across the EU by tech giants. Recently, the regulatory body sought an order to restrain or suspend X&#8217;s data processing activities on users for the development, training, and refinement of an AI system. This situation clearly depicts the growing conflict or tension experienced by nearly all EU states between AI advances and ongoing data protection concerns.</p>



<p>It seems that the order was issued too late by regulators and the court. In the response filed for the lawsuit, X, owned by Elon Musk, reported that Grok—an AI chatbot—allowed its users to skip their public posts.</p>



<p>As Judge Leonie Reynolds noted, X began processing European users&#8217; data for AI training on May 7, but the opt-out option was not introduced until July 16. Furthermore, it was not immediately made available to all users. Therefore, there was a period when the data was used without the users&#8217; consent.</p>



<p>X&#8217;s legal representation has assured the court that data obtained from EU users between May 7 and August 1 will not be used while the DPC&#8217;s order is under consideration. It is expected that X will file opposition papers arguing against the suspension order by September 4. This will set in motion what could be a court battle with effects reverberating throughout the EU.</p>



<p>Either way, X has not remained silent on the matter. In its <a target="_blank" href="https://twitter.com/GlobalAffairs/status/1820957979111297059" rel="noreferrer noopener">statement</a>, the company&#8217;s Global Government Affairs account on X noted that the DPC&#8217;s order was &#8220;unwarranted, overbroad, and singles out X without any justification.&#8221; Furthermore, the company expressed concerns that the order would undermine efforts to keep the platform safe and restrict its use of technologies in the EU. This highlights the complex balance between regulatory compliance and operational viability that tech companies must navigate in the current digital landscape.</p>



<p>The platform emphasised its proactive approach in working with regulators, including the DPC, regarding Grok since late 2023. X claims to have been fully transparent about the use of public data for AI models, including providing necessary legal assessments and engaging in lengthy discussions with regulators.</p>



<p>This regulatory action against X is not an isolated incident. Other tech giants have faced similar scrutiny in recent months. Meta Platforms recently decided to postpone the launch of its Meta AI models in Europe following advice from the Irish DPC. Similarly, Google agreed to delay and modify its Gemini AI chatbot earlier this year after consultations with the Irish regulator.</p>



<p>These developments collectively signal a shift in the regulatory landscape of AI and data usage in the EU. Regulators are taking a more active role in overseeing how tech companies utilise user data for AI training and development, reflecting growing concerns about data privacy and the ethical implications of AI advancement.</p>



<p>As the legal proceedings unfold, the outcome of this case could set important precedents for how AI development is regulated in the EU, potentially influencing global standards for data protection in the AI era. The tech industry and privacy advocates alike will be watching closely as this situation develops, recognising its potential to shape the future of AI innovation and data privacy regulations.</p>



<p><em>(Photo by <a href="https://unsplash.com/@alexbemore?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Alexander Shatov</a>)</em></p>



<p><strong>See also: <a target="_blank" href="https://www.artificialintelligence-news.com/news/balancing-innovation-trust-experts-assess-eu-ai-act/" rel="noreferrer noopener">Balancing innovation and trust: Experts assess the EU&#8217;s AI Act</a></strong></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/">X agrees to halt use of certain EU data for AI chatbot training</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/x-agrees-halt-use-certain-eu-data-ai-chatbot-training/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
