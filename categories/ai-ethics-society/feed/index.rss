<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>AI Ethics &amp; Society News | Ethical Considerations for AI | AI News</title>
	<atom:link href="https://www.artificialintelligence-news.com/categories/ai-ethics-society/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.artificialintelligence-news.com/categories/ai-ethics-society/</link>
	<description>Artificial Intelligence News</description>
	<lastBuildDate>Mon, 23 Dec 2024 14:09:30 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url>
	<title>AI Ethics &amp; Society News | Ethical Considerations for AI | AI News</title>
	<link>https://www.artificialintelligence-news.com/categories/ai-ethics-society/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>OpenAI funds $1 million study on AI and morality at Duke University</title>
		<link>https://www.artificialintelligence-news.com/news/openai-funds-1-million-study-on-ai-and-morality-at-duke-university/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=openai-funds-1-million-study-on-ai-and-morality-at-duke-university</link>
					<comments>https://www.artificialintelligence-news.com/news/openai-funds-1-million-study-on-ai-and-morality-at-duke-university/#respond</comments>
		
		<dc:creator><![CDATA[Muhammad Zulhusni]]></dc:creator>
		<pubDate>Mon, 23 Dec 2024 14:09:26 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ethical AI]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16784</guid>

					<description><![CDATA[<p>OpenAI is awarding a $1 million grant to a Duke University research team to look at how AI could predict human moral judgments. The initiative highlights the growing focus on the intersection of technology and ethics, and raises critical questions: Can AI handle the complexities of morality, or should ethical decisions remain the domain of<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/openai-funds-1-million-study-on-ai-and-morality-at-duke-university/" title="ReadOpenAI funds $1 million study on AI and morality at Duke University">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/openai-funds-1-million-study-on-ai-and-morality-at-duke-university/">OpenAI funds $1 million study on AI and morality at Duke University</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>OpenAI is awarding a $1 million grant to a Duke University research team to look at how AI could predict human moral judgments.</p>



<p>The <a href="https://www.eweek.com/news/openai-funding-ai-morality-research/" target="_blank" rel="noreferrer noopener">initiative</a> highlights the growing focus on the intersection of technology and ethics, and raises critical questions: Can AI handle the complexities of morality, or should ethical decisions remain the domain of humans?</p>



<p>Duke University’s Moral Attitudes and Decisions Lab (MADLAB), led by ethics professor Walter Sinnott-Armstrong and co-investigator Jana Schaich Borg, is in charge of the “Making Moral AI” project. The team envisions a “moral GPS,” a tool that could guide ethical decision-making.</p>



<p>Its research spans diverse fields, including computer science, philosophy, psychology, and neuroscience, to understand how moral attitudes and decisions are formed and how AI can contribute to the process.</p>



<h3 class="wp-block-heading">The role of AI in morality</h3>



<p>MADLAB’s work examines how AI might predict or influence moral judgments. Imagine an algorithm assessing ethical dilemmas, such as deciding between two unfavourable outcomes in autonomous vehicles or providing guidance on ethical business practices. Such scenarios underscore AI’s potential but also raise fundamental questions: Who determines the moral framework guiding these types of tools, and should AI be trusted to make decisions with ethical implications?</p>



<h3 class="wp-block-heading">OpenAI’s vision</h3>



<p>The grant supports the development of algorithms that forecast human moral judgments in areas such as medical, law, and business, which frequently involve complex ethical trade-offs. While promising, AI still struggles to grasp the emotional and cultural nuances of morality. Current systems excel at recognising patterns but lack the deeper understanding required for ethical reasoning.</p>



<p>Another concern is how this technology might be applied. While AI could assist in life-saving decisions, its use in defence strategies or surveillance introduces moral dilemmas. Can unethical AI actions be justified if they serve national interests or align with societal goals? These questions emphasise the difficulties of embedding morality into AI systems.</p>



<h3 class="wp-block-heading">Challenges and opportunities</h3>



<p>Integrating ethics into AI is a formidable challenge that requires collaboration across disciplines. Morality is not universal; it is shaped by cultural, personal, and societal values, making it difficult to encode into algorithms. Additionally, without safeguards such as transparency and accountability, there is a risk of perpetuating biases or enabling harmful applications.</p>



<p>OpenAI’s investment in Duke’s research marks at step toward understanding the role of AI in ethical decision-making. However, the journey is far from over. Developers and policymakers must work together to ensure that AI tools align with social values, and emphasise fairness and inclusivity while addressing biases and unintended consequences.</p>



<p>As AI becomes more integral to decision-making, its ethical implications demand attention. Projects like “Making Moral AI” offer a starting point for navigating a complex landscape, balancing innovation with responsibility in order to shape a future where technology serves the greater good.</p>



<p><em>(Photo by <a href="https://unsplash.com/photos/a-cell-phone-sitting-on-top-of-a-laptop-computer-7q-kE4SZzvQ?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>)</em></p>



<p><strong>See also: <a target="_blank" href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/" rel="noreferrer noopener">AI governance: Analysing emerging global regulations</a></strong></p>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a target="_blank" href="https://www.ai-expo.net/" rel="noreferrer noopener"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a target="_blank" href="https://intelligentautomation-conference.com/northamerica/" rel="noreferrer noopener">Intelligent Automation Conference</a>, <a target="_blank" href="https://www.blockchain-expo.com/" rel="noreferrer noopener">BlockX</a>,<a target="_blank" href="https://digitaltransformation-week.com/" rel="noreferrer noopener"> Digital Transformation Week</a>, and <a target="_blank" href="https://www.cybersecuritycloudexpo.com/" rel="noreferrer noopener">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a target="_blank" href="https://techforge.pub/events/" rel="noreferrer noopener">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/openai-funds-1-million-study-on-ai-and-morality-at-duke-university/">OpenAI funds $1 million study on AI and morality at Duke University</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/openai-funds-1-million-study-on-ai-and-morality-at-duke-university/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Ordnance Survey: Navigating the role of AI and ethical considerations in geospatial technology</title>
		<link>https://www.artificialintelligence-news.com/news/ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology</link>
					<comments>https://www.artificialintelligence-news.com/news/ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology/#respond</comments>
		
		<dc:creator><![CDATA[Duncan MacRae]]></dc:creator>
		<pubDate>Mon, 23 Dec 2024 07:09:00 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Companies]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[future]]></category>
		<category><![CDATA[geospatial technology]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16773</guid>

					<description><![CDATA[<p>As we approach a new year filled with potential, the landscape of technology, particularly artificial intelligence (AI) and machine learning (ML), is on the brink of significant transformation. Manish Jethwa, CTO at Ordnance Survey (OS), the national mapping agency for Great Britain, offers an insightful glimpse into what we can expect from these advancements and<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology/" title="ReadOrdnance Survey: Navigating the role of AI and ethical considerations in geospatial technology">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology/">Ordnance Survey: Navigating the role of AI and ethical considerations in geospatial technology</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>As we approach a new year filled with potential, the landscape of technology, particularly artificial intelligence (AI) and machine learning (ML), is on the brink of significant transformation. Manish Jethwa, CTO at Ordnance Survey (OS), the national mapping agency for Great Britain, offers an insightful glimpse into what we can expect from these advancements and their implications for the geospatial sector.</p>



<p><strong>Breaking Down Barriers with AI</strong></p>


<div class="wp-block-image">
<figure class="alignright size-full is-resized"><img fetchpriority="high" decoding="async" width="512" height="489" src="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394.jpg" alt="" class="wp-image-16778" style="width:314px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394.jpg 512w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394-300x287.jpg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394-209x200.jpg 209w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394-298x285.jpg 298w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394-262x250.jpg 262w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394-100x96.jpg 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Manish-ordnance-e1734707204394-60x57.jpg 60w" sizes="(max-width: 512px) 100vw, 512px" /></figure></div>


<p>Looking ahead, Jethwa anticipates continued significant advancements in AI and machine learning, particularly with the push towards Gen AI. According to him, the integration of large language models (LLMs) with more sophisticated agents will not only perform complex tasks on behalf of users but also further reduce barriers to interaction. This shift, especially in the geospatial field, means that translating natural language into precise data queries will become more seamless, ultimately making geospatial datasets more accessible, mainstream, and user-friendly.</p>



<p><strong>Training for Complex Tasks</strong></p>



<p>Beyond LLMs, Jethwa is optimistic about progress in the broader category of machine learning, driven by greater access to graphics processing units for training.</p>



<p>He says: “At Ordnance Survey (OS), we’ll leverage this capability to train models for specific, complex tasks such as automatic feature extraction from imagery.</p>



<p>“With an increasing volume of data generated automatically, hopefully next year will also bring innovative tools and techniques to validate data, ensuring it can be confidently utilised for its intended use.”</p>



<p>He underscores the importance of not only pursuing new capabilities but also ensuring that these tools are integrated responsibly into workflows, focusing on quality and risk management.</p>



<p><strong>The Ethical Frontier</strong></p>



<p>The rapid evolution of AI brings with it an urgent need for ethical considerations.&nbsp;</p>



<p>Jethwa explains: “I would like to see a greater emphasis on ethical AI and responsible technology development,&#8221; including creating AI systems that are “transparent, fair, and unbiased” while also considering their environmental and societal impact.</p>



<p>This focus on ethics is encapsulated in OS’s Responsible AI Charter, which guides their approach to integrating new techniques safely.</p>



<p>Moreover, Jethwa highlights the role of workforce development in successful transformations. He believes organisations must commit to “retraining and upskilling employees to prepare them for the impact of AI and digital transformation.”&nbsp;</p>



<p>This is vital to ensure that in the pursuit of enhanced efficiency, companies do not “lose the personality, creativity, and emotion that we bring as humans into the workplace.”&nbsp;</p>



<p><strong>Embracing Change While Managing Risks</strong></p>



<p>Despite the promise of technological advancements, obstacles remain in the journey toward digital transformation. Jethwa notes that challenges such as “cultural resistance and rapid successive changes leading to change fatigue will likely persist.” </p>



<p>He advocates for a careful balance between adopting new technologies and addressing the human elements of transformation processes.</p>



<p>As AI continues to influence various aspects of business, from decision-making to risk management, the issue of cybersecurity also looms large. Jethwa points out that “cybersecurity threats being powered by AI are becoming more sophisticated,” urging companies to develop comprehensive strategies that cover everything from data storage to analysis documentation.</p>



<p><strong>The Imperative to Progress</strong></p>



<p>In an evolving landscape, organisations that stagnate risk falling behind their competitors. Jethwa explains: “Companies that fail to keep up open themselves up to risks, such as changing customer expectations as well as attracting and retaining talent.”&nbsp;</p>



<p>He also emphasises the need for a “clear vision of future goals, effective communication of progress, and celebrating milestones to sustain momentum” in digital transformation initiatives.</p>



<p>As we move into a new year filled with promise, the future of AI and geospatial technology holds transformative power &#8211; but it must be used responsibly. The path that lies ahead in 2025 requires vigilance, an unwavering commitment to ethical practices and a human touch in order to drive successful innovation.</p>



<p><em>(Photos by <a href="https://unsplash.com/@anniespratt">Annie Spratt</a> and Ordnance Survey)</em></p>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong>&nbsp;Check out<a href="https://www.ai-expo.net/">&nbsp;AI &amp; Big Data Expo</a>&nbsp;taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including&nbsp;<a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>,&nbsp;<a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/">&nbsp;Digital Transformation Week</a>, and&nbsp;<a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge&nbsp;<a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology/">Ordnance Survey: Navigating the role of AI and ethical considerations in geospatial technology</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/ordnance-survey-navigating-the-role-of-ai-and-ethical-considerations-in-geospatial-technology/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>AI governance: Analysing emerging global regulations</title>
		<link>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=ai-governance-analysing-emerging-global-regulations</link>
					<comments>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Thu, 19 Dec 2024 16:21:18 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ai act]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[China]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[eu]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[framework]]></category>
		<category><![CDATA[governance]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Legislation]]></category>
		<category><![CDATA[privacy]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[risks]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[usa]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16742</guid>

					<description><![CDATA[<p>Governments are scrambling to establish regulations to govern AI, citing numerous concerns over data privacy, bias, safety, and more. AI News caught up with Nerijus Šveistys, Senior Legal Counsel at Oxylabs, to understand the state of play when it comes to AI regulation and its potential implications for industries, businesses, and innovation. “The boom of<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/" title="ReadAI governance: Analysing emerging global regulations">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/">AI governance: Analysing emerging global regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Governments are scrambling to establish regulations to govern AI, citing numerous concerns over data privacy, bias, safety, and more.</p>


<div class="wp-block-image">
<figure class="alignright size-full is-resized"><img decoding="async" width="800" height="800" src="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs.jpeg" alt="" class="wp-image-16743" style="width:174px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs.jpeg 800w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-300x300.jpeg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-150x150.jpeg 150w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-768x768.jpeg 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-125x125.jpeg 125w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-200x200.jpeg 200w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-285x285.jpeg 285w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-250x250.jpeg 250w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-100x100.jpeg 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-60x60.jpeg 60w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-400x400.jpeg 400w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-600x600.jpeg 600w" sizes="(max-width: 800px) 100vw, 800px" /></figure></div>


<p>AI News caught up with Nerijus Šveistys, Senior Legal Counsel at <a href="https://oxylabs.io/">Oxylabs</a>, to understand the state of play when it comes to AI regulation and its potential implications for industries, businesses, and innovation.</p>



<p>“The boom of the last few years appears to have sparked a push to establish regulatory frameworks for AI governance,” explains Šveistys.</p>



<p>“This is a natural development, as the rise of AI seems to pose issues in data privacy and protection, bias and discrimination, safety, intellectual property, and other legal areas, as well as ethics that need to be addressed.”</p>



<h3 class="wp-block-heading">Regions diverge in regulatory strategy</h3>



<p>The European Union’s <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">AI Act</a> has, unsurprisingly, positioned the region with a strict, centralised approach. The regulation, which came into force this year, is set to be fully effective by 2026.</p>



<p>Šveistys pointed out that the EU has acted relatively swiftly compared to other jurisdictions: “The main difference we can see is the comparative quickness with which the EU has released a uniform regulation to govern the use of all types of AI.”</p>



<p>Meanwhile, other regions have opted for more piecemeal approaches. China, for instance, has been implementing regulations specific to certain AI technologies in a phased-out manner. According to Šveistys, China began regulating AI models as early as 2021.</p>



<p>“In 2021, they introduced regulation on recommendation algorithms, which [had] increased their capabilities in digital advertising. It was followed by regulations <a href="https://www.artificialintelligence-news.com/news/chinas-deepfake-laws-come-into-effect-today/">on deep synthesis models</a> or, in common terms, deepfakes and content generation in 2022,” he said.</p>



<p>“Then, in 2023, regulation on generative AI models was introduced as these models were making a splash in commercial usage.”</p>



<p>The US, in contrast, remains relatively uncoordinated in its approach. Federal-level regulations are yet to be enacted, with efforts mostly emerging at the state level.</p>



<p>“There are proposed regulations at the state level, such as the so-called California AI Act, but even if they come into power, it may still take some time before they do,” Šveistys noted.</p>



<p>This delay in implementing unified AI regulations in the US has raised questions about the extent to which business pushback may be contributing to the slow rollout. Šveistys said that while lobbyist pressure is a known factor, it’s not the only potential reason.</p>



<p>“There was <a href="https://www.artificialintelligence-news.com/news/tech-industry-giants-urge-eu-streamline-ai-regulations/">pushback to the EU AI Act</a>, too, which was nevertheless introduced. Thus, it is not clear whether the delay in the US is only due to lobbyism or other obstacles in the legislation enactment process,” explains Šveistys.</p>



<p>“It might also be because some still see AI as a futuristic concern, not fully appreciating the extent to which it is already a legal issue of today.”</p>



<h3 class="wp-block-heading">Balancing innovation and safety</h3>



<p>Differentiated regulatory approaches could affect the pace of innovation and business competitiveness across regions.</p>



<p>Europe’s regulatory framework, though more stringent, aims to ensure consumer protection and ethical adherence—something that less-regulated environments may lack.</p>



<p>“More rigid regulatory frameworks may impose compliance costs for businesses in the AI field and stifle competitiveness and innovation. On the other hand, they bring the benefits of protecting consumers and adhering to certain ethical norms,” comments Šveistys.</p>



<p>This trade-off is especially pronounced in AI-related sectors such as targeted advertising, where algorithmic bias is increasingly scrutinised.</p>



<p>AI governance often extends beyond laws that specifically target AI, incorporating related legal areas like those governing data collection and privacy. For example, the EU AI Act also regulates the use of AI in physical devices, such as elevators.</p>



<p>&#8220;Additionally, all businesses that collect data for advertisement are potentially affected as AI regulation can also cover algorithmic bias in targeted advertising,&#8221; emphasises Šveistys.</p>



<h3 class="wp-block-heading">Impact on related industries</h3>



<p>One industry that is deeply intertwined with AI developments is web scraping. Typically used for collecting publicly available data, web scraping is undergoing an AI-driven evolution.</p>



<p>&#8220;From data collection, validation, analysis, or overcoming anti-scraping measures, there is a lot of potential for AI to massively improve the efficiency, accuracy, and adaptability of web scraping operations,&#8221; said Šveistys.&nbsp;</p>



<p>However, as AI regulation and related laws tighten, web scraping companies will face greater scrutiny.</p>



<p>“AI regulations may also bring the spotlight on certain areas of law that were always very relevant to the web scraping industry, such as privacy or copyright laws,” Šveistys added.</p>



<p>“At the end of the day, scraping content protected by such laws without proper authorisation could always lead to legal issues, and now so can using AI this way.”</p>



<h3 class="wp-block-heading">Copyright battles and legal precedents</h3>



<p>The implications of AI regulation are also playing out on a broader legal stage, particularly in cases involving generative AI tools.</p>



<p>High-profile <a href="https://www.artificialintelligence-news.com/news/openai-and-microsoft-lawsuit-github-copilot/">lawsuits</a> have been launched against AI giants like OpenAI and its primary backer, Microsoft, by authors, artists, and musicians who claim their copyrighted materials were used to train AI systems without proper permission.</p>



<p>“These cases are pivotal in determining the legal boundaries of using copyrighted material for AI development and establishing legal precedents for protecting intellectual property in the digital age,” said Šveistys.</p>



<p>While these lawsuits could take years to resolve, their outcomes may fundamentally shape the future of AI development. So, what can businesses do now as the regulatory and legal landscape continues to evolve?</p>



<p>“Speaking about the specific cases of using copyrighted material for AI training, businesses should approach this the same way as any web-scraping activity – that is, evaluate the specific data they wish to collect with the help of a legal expert in the field,” recommends Šveistys.</p>



<p>“It is important to recognise that the AI legal landscape is very new and rapidly evolving, with not many precedents in place to refer to as of yet. Hence, continuous monitoring and adaptation of your AI usage are crucial.”</p>



<p>Just this week, the UK Government made headlines with its announcement of a consultation on the use of copyrighted material for training AI models. Under the proposals, tech firms could be permitted to use copyrighted material unless owners have specifically opted out.</p>



<p>Despite the diversity of approaches globally, the AI regulatory push marks a significant moment for technological governance. Whether through the EU’s comprehensive model, China’s step-by-step strategy, or narrower, state-level initiatives like in the US, businesses worldwide must navigate a complex, evolving framework.</p>



<p>The challenge ahead will be striking the right balance between fostering innovation and mitigating risks, ensuring that AI remains a force for good while avoiding potential harms.</p>



<p><em>(Photo by <a href="https://unsplash.com/@nathangbingle?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Nathan Bingle</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:844px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/">AI governance: Analysing emerging global regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>UK wants to prove AI can modernise public services responsibly</title>
		<link>https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=uk-wants-prove-ai-can-modernise-public-services-responsibly</link>
					<comments>https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Wed, 18 Dec 2024 15:37:46 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[innovation]]></category>
		<category><![CDATA[public sector]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[strategy]]></category>
		<category><![CDATA[uk]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16736</guid>

					<description><![CDATA[<p>The UK Government wants to prove that AI is being deployed responsibly within public services to speed up decision-making, reduce backlogs, and enhance support for citizens. New records, part of the Algorithmic Transparency Recording Standard (ATRS), were published this week to shed light on the AI tools being used and set a benchmark for transparency<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/" title="ReadUK wants to prove AI can modernise public services responsibly">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/">UK wants to prove AI can modernise public services responsibly</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The UK Government wants to prove that AI is being deployed responsibly within public services to speed up decision-making, reduce backlogs, and enhance support for citizens.</p>



<p>New records, part of the Algorithmic Transparency Recording Standard (ATRS), were <a href="https://www.gov.uk/algorithmic-transparency-records">published</a> this week to shed light on the AI tools being used and set a benchmark for transparency and accountability in the integration of technology in public service delivery.</p>



<p>The initiative is part of the government’s broader strategy to embrace technology to improve outcomes, echoing commitments outlined in the <a href="https://www.gov.uk/missions">&#8220;Plan for Change&#8221;</a> to modernise public services and drive economic growth through innovative solutions.</p>



<h3 class="wp-block-heading">The power of AI for modernisation</h3>



<p>Among the published records, the Foreign, Commonwealth and Development Office is leveraging AI to provide faster responses to Britons seeking assistance overseas. Similarly, the Ministry of Justice is utilising algorithms to help researchers gain a deeper understanding of how individuals interact with the justice system, while other departments are deploying AI to enhance job advertisements.</p>



<p>The ATRS aims to document how such algorithmic tools are utilised and ensure their responsible application. By doing so, the government hopes to strengthen public trust in these innovations while encouraging their continued adoption across sectors.</p>



<p>Speaking on the government’s approach, Science Secretary Peter Kyle remarked:&nbsp;&nbsp;</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;Technology has huge potential to transform public services for the better; we will put it to use to cut backlogs, save money, and improve outcomes for citizens across the country.</em></p>



<p><em>Transparency in how and why the public sector is using algorithmic tools is crucial to ensure that they are trusted and effective. That is why we will continue to take bold steps like releasing these records to make sure everyone is clear on how we are applying and trialling technology as we use it to bring public services back from the brink.&#8221;</em></p>
</blockquote>



<p>Specifically, the Department for Business and Trade has highlighted its algorithmic tool designed to predict which companies are likely to export goods internationally.</p>



<p>The AI-driven approach allows officials to target support towards high-growth potential businesses, enabling them to reach global markets faster. Previously reliant on time-consuming manual methods to analyse the more than five million companies registered on Companies House, this advancement ensures better allocation of resources and expedited assistance.</p>



<p>Business Secretary Jonathan Reynolds said:&nbsp;&nbsp;</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;Our Plan for Change will deliver economic growth, and for that to succeed, we need to support companies across the UK to realise their full potential when it comes to exporting around the globe.</em></p>



<p><em>Our use of AI plays a vital and growing role in that mission, allowing high-growth businesses to maximise the export opportunities available to them, while ensuring that we are using taxpayers’ money responsibly and efficiently in delivering economic stability.&#8221;</em></p>
</blockquote>



<h3 class="wp-block-heading">Establishing clear guidelines for AI in public services</h3>



<p>To bolster public trust, new guidelines have been announced to clarify the scope of algorithmic transparency records.</p>



<p>Central government organisations will need to publish a record for any algorithmic tool that interacts directly with citizens or plays a significant role in decision-making about individuals. Limited exceptions, such as those concerning national security, apply.&nbsp;&nbsp;</p>



<p>These records will be published once tools are piloted publicly or have become operational. They will detail the data used to train AI models, the underlying technologies, and the measures implemented to mitigate risks.</p>



<p>Importantly, the records also seek to confirm that – while AI tools are used to accelerate decision-making processes – human oversight remains integral, with trained staff responsible for final decisions.</p>



<p>Dr Antonio Espingardeiro, a member of <a href="https://www.ieee.org/">IEEE</a> and an expert in software and robotics, commented:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;AI has the potential to radically transform the public sector. In recent years, we have seen AI become a credible part of everyday public services. As it becomes more sophisticated, AI can conduct data-heavy tasks traditionally undertaken by humans. It can analyse vast quantities of information and, when coupled with machine learning, search through records and infer patterns or anomalies in data that would otherwise take decades for humans to analyse.</em></p>



<p><em>With this announcement, the UK government has acknowledged AI’s potential and proven that technology investment is essential to improving outcomes and the delivery of vital services. Over time, machine learning and generative AI (GenAI) could bring substantial value to the public system. With increased adoption, we will soon be able to deliver the scalability that the public sector needs and relieve the pressures and workloads placed on staff.&#8221;</em></p>
</blockquote>



<p>Eleanor Watson, also a member of IEEE and an AI ethics engineer affiliated with <a href="https://www.su.org/">Singularity University</a>, added:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;With AI growing more rapidly than ever before, and already being tested and employed in education, healthcare, transportation, finance, data security, and more, the government, tech leaders, and academia should work together to establish standards and regulations for safe and responsible development of AI-based systems. This way, AI can be used to its full potential as indicated with this latest announcement.</em></p>



<p><em>Data privacy is probably the most critical ethical consideration, requiring informed consent, data anonymisation, strict access controls, secure storage, and compliance. New techniques such as homomorphic encryption, zero-knowledge proofs, federated learning, and part-trained models can help models to make use of our personal data in an encrypted form.&#8221;</em></p>
</blockquote>



<p>Transparency remains a key tenet of the UK Government’s AI strategy. This announcement follows a recent statement by Pat McFadden, Chancellor of the Duchy of Lancaster, who affirmed that the benefits of technology – particularly AI – must span both public and private sectors and be used to modernise government.</p>



<p>As the Science Secretary’s department solidifies government efforts to create a &#8220;digital centre,&#8221; it marks a major step forward in boosting the responsible and effective use of AI across the UK’s public sector.</p>



<p>The ATRS records offer a valuable template for how governments worldwide can deploy AI systems to maximise efficiency, grow transparency, and balance the need for innovation with ethical considerations.</p>



<p><em>(Photo by <a href="https://unsplash.com/@shreyasdbz?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Shreyas Sane</a>)</em></p>



<p><strong><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/"><strong>MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</strong></a></strong></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:1082px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/">UK wants to prove AI can modernise public services responsibly</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Machine unlearning: Researchers make AI models ‘forget’ data</title>
		<link>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=machine-unlearning-researchers-ai-models-forget-data</link>
					<comments>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Tue, 10 Dec 2024 17:18:26 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[privacy]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16680</guid>

					<description><![CDATA[<p>Researchers from the Tokyo University of Science (TUS) have developed a method to enable large-scale AI models to selectively &#8220;forget&#8221; specific classes of data. Progress in AI has provided tools capable of revolutionising various domains, from healthcare to autonomous driving. However, as technology advances, so do its complexities and ethical considerations.&#160; The paradigm of large-scale<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/" title="ReadMachine unlearning: Researchers make AI models ‘forget’ data">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/">Machine unlearning: Researchers make AI models ‘forget’ data</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Researchers from the <a href="https://www.tus.ac.jp/en/">Tokyo University of Science</a> (TUS) have developed a method to enable large-scale AI models to selectively &#8220;forget&#8221; specific classes of data.</p>



<p>Progress in AI has provided tools capable of revolutionising various domains, from healthcare to autonomous driving. However, as technology advances, so do its complexities and ethical considerations.&nbsp;</p>



<p>The paradigm of large-scale pre-trained AI systems, such as OpenAI’s ChatGPT and <a href="https://openai.com/index/clip/">CLIP</a> (Contrastive Language–Image Pre-training), has reshaped expectations for machines. These highly generalist models, capable of handling a vast array of tasks with consistent precision, have seen widespread adoption for both professional and personal use.&nbsp;&nbsp;</p>



<p>However, such versatility comes at a hefty price. Training and running these models demands prodigious amounts of energy and time, raising sustainability concerns, as well as requiring cutting-edge hardware significantly more expensive than standard computers. Compounding these issues is that generalist tendencies may hinder the efficiency of AI models when applied to specific tasks.&nbsp;&nbsp;</p>



<p>For instance, “in practical applications, the classification of all kinds of object classes is rarely required,” explains Associate Professor Go Irie, who led the research. “For example, in an autonomous driving system, it would be sufficient to recognise limited classes of objects such as cars, pedestrians, and traffic signs.</p>



<p>“We would not need to recognise food, furniture, or animal species. Retaining classes that do not need to be recognised may decrease overall classification accuracy, as well as cause operational disadvantages such as the waste of computational resources and the risk of information leakage.”&nbsp;&nbsp;</p>



<p>A potential solution lies in training models to “forget” redundant or unnecessary information—streamlining their processes to focus solely on what is required. While some existing methods already cater to this need, they tend to assume a “white-box” approach where users have access to a model’s internal architecture and parameters. Oftentimes, however, users get no such visibility.&nbsp;&nbsp;</p>



<p>“Black-box” AI systems, more common due to commercial and ethical restrictions, conceal their inner mechanisms, rendering traditional forgetting techniques impractical. To address this gap, the research team turned to derivative-free optimisation—an approach that sidesteps reliance on the inaccessible internal workings of a model.&nbsp;&nbsp;</p>



<h3 class="wp-block-heading">Advancing through forgetting</h3>



<p>The study, set to be presented at the Neural Information Processing Systems (NeurIPS) conference in 2024, introduces a methodology dubbed “black-box forgetting.”</p>



<p>The process modifies the input prompts (text instructions fed to models) in iterative rounds to make the AI progressively &#8220;forget&#8221; certain classes. Associate Professor Irie collaborated on the work with co-authors Yusuke Kuwana and Yuta Goto (both from TUS), alongside Dr Takashi Shibata from <a href="https://www.nec.com/">NEC Corporation</a>.&nbsp;&nbsp;</p>



<p>For their experiments, the researchers targeted CLIP, a vision-language model with image classification abilities. The method they developed is built upon the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), an evolutionary algorithm designed to optimise solutions step-by-step. In this study, CMA-ES was harnessed to evaluate and hone prompts provided to CLIP, ultimately suppressing its ability to classify specific image categories.</p>



<p>As the project progressed, challenges arose. Existing optimisation techniques struggled to scale up for larger volumes of targeted categories, leading the team to devise a novel parametrisation strategy known as &#8220;latent context sharing.&#8221;&nbsp;&nbsp;</p>



<p>This approach breaks latent context – a representation of information generated by prompts – into smaller, more manageable pieces. By allocating certain elements to a single token (word or character) while reusing others across multiple tokens, they dramatically reduced the problem&#8217;s complexity. Crucially, this made the process computationally tractable even for extensive forgetting applications.&nbsp;&nbsp;</p>



<p>Through benchmark tests on multiple image classification datasets, the researchers validated the efficacy of black-box forgetting—achieving the goal of making CLIP &#8220;forget&#8221; approximately 40% of target classes without direct access to the AI model&#8217;s internal architecture.</p>



<p>This research marks the first successful attempt to induce selective forgetting in a black-box vision-language model, demonstrating promising results.&nbsp;&nbsp;</p>



<h3 class="wp-block-heading">Benefits of helping AI models forget data</h3>



<p>Beyond its technical ingenuity, this innovation holds significant potential for real-world applications where task-specific precision is paramount.</p>



<p>Simplifying models for specialised tasks could make them faster, more resource-efficient, and capable of running on less powerful devices—hastening the adoption of AI in areas previously deemed unfeasible.&nbsp;&nbsp;</p>



<p>Another key use lies in image generation, where forgetting entire categories of visual context could prevent models from inadvertently creating undesirable or harmful content, be it offensive material or misinformation.&nbsp;&nbsp;</p>



<p>Perhaps most importantly, this method addresses one of AI’s greatest ethical quandaries: <a href="https://www.artificialintelligence-news.com/categories/privacy/">privacy</a>.</p>



<p>AI models, particularly large-scale ones, are often trained on massive datasets that may inadvertently contain sensitive or outdated information. Requests to remove such data—especially in light of laws advocating for the “Right to be Forgotten”—pose significant challenges.</p>



<p>Retraining entire models to exclude problematic data is costly and time-intensive, yet the risks of leaving it unaddressed can have far-reaching consequences.</p>



<p>“Retraining a large-scale model consumes enormous amounts of energy,” notes Associate Professor Irie. “‘Selective forgetting,’ or so-called machine unlearning, may provide an efficient solution to this problem.”&nbsp;&nbsp;</p>



<p>These privacy-focused applications are especially relevant in high-stakes industries like <a href="https://www.artificialintelligence-news.com/categories/ai-industries/healthcare/">healthcare</a> and <a href="https://www.artificialintelligence-news.com/news/large-language-models-could-revolutionsise-the-finance-sector-within-two-years/">finance</a>, where sensitive data is central to operations.&nbsp;&nbsp;</p>



<p>As the global race to advance AI accelerates, the Tokyo University of Science’s black-box forgetting approach charts an important path forward—not only by making the technology more adaptable and efficient but also by adding significant safeguards for users.&nbsp;&nbsp;</p>



<p>While the potential for misuse remains, methods like selective forgetting demonstrate that researchers are proactively addressing both ethical and practical challenges.&nbsp;&nbsp;</p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/why-qwq-32b-preview-is-the-reasoning-ai-to-watch/"><strong>Why QwQ-32B-Preview is the reasoning AI to watch</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:769px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/">Machine unlearning: Researchers make AI models ‘forget’ data</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</title>
		<link>https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=mhra-pilots-ai-airlock-accelerate-healthcare-adoption</link>
					<comments>https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Wed, 04 Dec 2024 11:46:32 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Healthcare]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[health]]></category>
		<category><![CDATA[healthcare]]></category>
		<category><![CDATA[medicine]]></category>
		<category><![CDATA[mhra]]></category>
		<category><![CDATA[nhs]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[uk]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16631</guid>

					<description><![CDATA[<p>The Medicines and Healthcare products Regulatory Agency (MHRA) has announced the selection of five healthcare technologies for its ‘AI Airlock’ scheme. AI Airlock aims to refine the process of regulating AI-driven medical devices and help fast-track their safe introduction to the UK’s National Health Service (NHS) and patients in need. The technologies chosen for this<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/" title="ReadMHRA pilots ‘AI Airlock’ to accelerate healthcare adoption">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/">MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The Medicines and Healthcare products Regulatory Agency (<a href="https://www.gov.uk/government/organisations/medicines-and-healthcare-products-regulatory-agency">MHRA</a>) has announced the selection of five healthcare technologies for its ‘AI Airlock’ scheme.</p>



<p>AI Airlock aims to refine the process of regulating AI-driven medical devices and help fast-track their safe introduction to the UK’s National Health Service (NHS) and patients in need.</p>



<p>The technologies chosen for this scheme include solutions targeting cancer and chronic respiratory diseases, as well as advancements in radiology diagnostics. These AI systems promise to revolutionise the accuracy and efficiency of healthcare, potentially driving better diagnostic tools and patient care.</p>



<p>The AI Airlock, as described by the MHRA, is a “sandbox” environment—an experimental framework designed to help manufacturers determine how best to collect real-world evidence to support the regulatory approval of their devices.</p>



<p>Unlike traditional medical devices, AI models continue to evolve through learning, making the establishment of safety and efficacy evidence more complex. The Airlock enables this exploration within a monitored virtual setting, giving developers insight into the practical challenges of regulation while supporting the NHS’s broader adoption of transformative AI technologies.</p>



<h3 class="wp-block-heading">Safely enabling AI healthcare innovation&nbsp;&nbsp;</h3>



<p>Laura Squire, the lead figure in MedTech regulatory reform and Chief Officer at the MHRA, said: “New AI medical devices have the potential to increase the accuracy of healthcare decisions, save time, and improve efficiency—leading to better outcomes for the NHS and patients across all healthcare settings.&nbsp;</p>



<p>“But we need to be confident that AI-powered medical devices introduced into the NHS are safe, stay safe, and perform as intended through their lifetime of use.”</p>



<p>Squire emphasised that the AI Airlock pilot allows collaboration “in partnership with technology specialists, developers and the NHS,” facilitating the exploration of best practices and accelerating safe patient access to innovative solutions.</p>



<p>Government representatives have praised the initiative for its forward-thinking framework.</p>



<p>Karin Smyth, Minister of State for Health, commented: “As part of our 10-Year Health Plan, we’re shifting NHS care from analogue to digital, and this project will help bring the most promising technology to patients.</p>



<p>“AI has the power to revolutionise care by supporting doctors to diagnose diseases, automating time-consuming admin tasks, and reducing hospital admissions by predicting future ill health.”</p>



<p>Science Minister Lord Vallance lauded the AI Airlock pilot as “a great example of government working with businesses to enable them to turn ideas into products that improve lives.” He added, “This shows how good regulation can facilitate emerging technologies for the benefit of the UK and our economy.”</p>



<h3 class="wp-block-heading">Selected technologies&nbsp;&nbsp;</h3>



<p>The deployment of AI-powered medical devices requires meeting stringent criteria to ensure innovation, patient benefits, and regulatory challenge readiness. The five technologies selected for this inaugural pilot offer vital insights into healthcare’s future:&nbsp;</p>



<ol class="wp-block-list">
<li><strong>Lenus Stratify</strong></li>
</ol>



<p>Patients with Chronic Obstructive Pulmonary Disease (COPD) are among those who stand to benefit significantly from AI innovation. Lenus Stratify, developed by Lenus Health, analyses patient data to predict severe lung disease outcomes, reducing unscheduled hospital admissions. The system empowers care providers to adopt earlier interventions, affording patients an improved quality of life while alleviating NHS resource strain.&nbsp;&nbsp;</p>



<ol start="2" class="wp-block-list">
<li><strong>Philips Radiology Reporting Enhancer</strong></li>
</ol>



<p>Philips has integrated AI into existing radiology workflows to enhance the efficiency and accuracy of critical radiology reports. This system uses AI to prepare the “Impression” section of reports, summarising essential diagnostic information for healthcare providers. By automating this process, Philips aims to minimise workload struggles, human errors, and miscommunication, creating a more seamless diagnostic experience.&nbsp;&nbsp;</p>



<ol start="3" class="wp-block-list">
<li><strong>Federated AI Monitoring Service (FAMOS)</strong></li>
</ol>



<p>One recurring AI challenge is the concept of “drift,” when changing real-world conditions impair system performance over time. Newton’s Tree has developed FAMOS to monitor AI models in real time, flagging degradation and enabling rapid corrections. Hospitals, regulators, and software developers can use this tool to ensure algorithms remain high-performing, adapting to evolving circumstances while prioritising patient safety.&nbsp;&nbsp;</p>



<ol start="4" class="wp-block-list">
<li><strong>OncoFlow Personalised Cancer Management</strong></li>
</ol>



<p>Targeting the pressing healthcare challenge of reducing waiting times for cancer treatment, OncoFlow speeds up clinical workflows through its intelligent care pathway platform. Initially applied to breast cancer protocols, the system later aims to expand across other oncology domains. With quicker access to tailored therapies, patients gain increased survival rates amidst mounting NHS pressures.&nbsp;&nbsp;</p>



<ol start="5" class="wp-block-list">
<li><strong>SmartGuideline</strong></li>
</ol>



<p>Developed to simplify complex clinical decision-making processes, SmartGuideline uses large-language AI trained on official NICE medical guidelines. This technology allows clinicians to ask routine questions and receive verified, precise answers, eliminating the ambiguity associated with current AI language models. By integrating this tool, patients benefit from more accurate treatments grounded in up-to-date medical knowledge.&nbsp;&nbsp;</p>



<h3 class="wp-block-heading">Broader implications&nbsp;&nbsp;</h3>



<p>The influence of the AI Airlock extends beyond its current applications. The MHRA expects pilot findings, due in 2025, to inform future medical device regulations and create a clearer path for manufacturers developing AI-enabled technologies.&nbsp;</p>



<p>The evidence derived will contribute to shaping post-Brexit UKCA marking processes, helping manufacturers achieve compliance with higher levels of transparency. By improving regulatory frameworks, the UK could position itself as a global hub for med-tech innovation while ensuring faster access to life-saving tools.</p>



<p>The urgency of these developments was underscored earlier this year in Lord Darzi’s <a href="https://www.gov.uk/government/publications/independent-investigation-of-the-nhs-in-england">review</a> of health and care. The report outlined the “critical state” of the NHS, offering AI interventions as a promising pathway to sustainability. The work on AI Airlock by the MHRA addresses one of the report’s major recommendations for enabling regulatory solutions and “unlocking the AI revolution” for healthcare advancements.</p>



<p>While being selected into the AI Airlock pilot does not indicate regulatory approval, the technologies chosen represent a potential leap forward in applying AI to some of healthcare’s most pressing challenges. The coming years will test the potential of these solutions under regulatory scrutiny.</p>



<p>If successful, the initiative from the MHRA could redefine how pioneering technologies like AI are adopted in <a href="https://www.artificialintelligence-news.com/categories/ai-industries/healthcare/">healthcare</a>, balancing the need for speed, safety, and efficiency. With the NHS under immense pressure from growing demand, AI’s ability to augment clinicians, predict illnesses, and streamline workflows may well be the game-changer the system urgently needs.</p>



<p><em>(Photo by <a href="https://unsplash.com/@nci?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">National Cancer Institute</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/ais-role-in-helping-to-prevent-skin-cancer-through-behaviour-change/"><strong>AI’s role in helping to prevent skin cancer through behaviour change</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:969px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/">MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Salesforce: UK set to lead agentic AI revolution</title>
		<link>https://www.artificialintelligence-news.com/news/salesforce-uk-set-lead-agentic-ai-revolution/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=salesforce-uk-set-lead-agentic-ai-revolution</link>
					<comments>https://www.artificialintelligence-news.com/news/salesforce-uk-set-lead-agentic-ai-revolution/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Mon, 02 Dec 2024 13:24:31 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Companies]]></category>
		<category><![CDATA[Enterprise]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Virtual Assistants]]></category>
		<category><![CDATA[adoption]]></category>
		<category><![CDATA[agentic ai]]></category>
		<category><![CDATA[agents]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[Business]]></category>
		<category><![CDATA[enterprise]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[productivity]]></category>
		<category><![CDATA[report]]></category>
		<category><![CDATA[research]]></category>
		<category><![CDATA[salesforce]]></category>
		<category><![CDATA[study]]></category>
		<category><![CDATA[uk]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16601</guid>

					<description><![CDATA[<p>Salesforce has unveiled the findings of its UK AI Readiness Index, signalling the nation is in a position to spearhead the next wave of AI innovation, also known as agentic AI. The report places the UK ahead of its G7 counterparts in terms of AI adoption but also underscores areas ripe for improvement, such as<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/salesforce-uk-set-lead-agentic-ai-revolution/" title="ReadSalesforce: UK set to lead agentic AI revolution">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/salesforce-uk-set-lead-agentic-ai-revolution/">Salesforce: UK set to lead agentic AI revolution</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Salesforce has unveiled the findings of its <a href="https://www.salesforce.com/uk/news/wp-content/uploads/sites/5/2024/12/Salesforce-UK-AI-Readiness-Index.pdf">UK AI Readiness Index</a>, signalling the nation is in a position to spearhead the next wave of AI innovation, also known as agentic AI.</p>



<p>The report places the UK ahead of its G7 counterparts in terms of AI adoption but also underscores areas ripe for improvement, such as support for SMEs, fostering cross-sector partnerships, and investing in talent development.</p>



<p>Zahra Bahrololoumi CBE, UKI CEO at Salesforce, commented: “Agentic AI is revolutionising enterprise software by enabling humans and agents to collaborate seamlessly and drive customer success.</p>



<p>“The UK AI Readiness Index positively highlights that the UK has both the vision and infrastructure to be a powerhouse globally in AI, and lead the current third wave of agentic AI.”</p>



<h3 class="wp-block-heading">UK AI adoption sets the stage for agentic revolution</h3>



<p>The Index details how both the public and private sectors in the UK have embraced AI&#8217;s transformative potential. With a readiness score of 65.5, surpassing the G7 average of 61.2, the UK is establishing itself as a hub for large-scale AI projects, driven by a robust innovation culture and pragmatic regulatory approaches.</p>



<p>The government has played its part in maintaining a stable and secure environment for tech investment. Initiatives such as the <a href="https://www.artificialintelligence-news.com/news/uk-reveals-ai-safety-summit-opening-day-agenda/">AI Safety Summit</a> at Bletchley Park and risk-oriented AI legislation showcase Britain&#8217;s leadership on critical AI issues like transparency and privacy.</p>



<p>Business readiness is equally impressive, with UK industries scoring 52, well above the G7 average of 47.8. SMEs in the UK are increasingly prioritising AI adoption, further bolstering the nation&#8217;s stance in the international AI arena.</p>



<p>Adam Evans, EVP &amp; GM of Salesforce AI Platform, is optimistic about the evolution of agentic AI. Evans foresees that, by 2025, these agents will become business-aware—expertly navigating industry-specific challenges to execute meaningful tasks and decisions.</p>



<h3 class="wp-block-heading">Investments fuelling AI growth</h3>



<p>Salesforce is committing $4 billion to the UK’s AI ecosystem over the next five years. Since establishing its UK AI Centre in London, Salesforce says it has engaged over 3,000 stakeholders in AI training and workshops.</p>



<p>Key investment focuses include creating a regulatory bridge between the EU’s <a href="https://www.artificialintelligence-news.com/news/balancing-innovation-trust-experts-assess-eu-ai-act/">rules-based approach</a> and the more relaxed US approach, and ensuring SMEs have the resources to integrate AI. A strong emphasis also lies on enhancing digital skills and centralising training to support the AI workforce of the future.</p>



<p>Feryal Clark, Minister for AI and Digital Government, said: &#8220;These findings are further proof the UK is in prime position to take advantage of AI, and highlight our strength in spurring innovation, investment, and collaboration across the public and private sector.</p>



<p>“There is a global race for AI and we’ll be setting out plans for how the UK can use the technology to ramp-up adoption across the economy, kickstart growth, and build an AI sector which can scale and compete on the global stage.”</p>



<p>Antony Walker, Deputy CEO at techUK, added: “To build this progress, government and industry must collaborate to foster innovation, support SMEs, invest in skills, and ensure flexible regulation, cementing the UK’s leadership in the global AI economy.”</p>



<h3 class="wp-block-heading">Agentic AI boosting UK business productivity&nbsp;</h3>



<p>Capita, Secret Escapes, Heathrow, and Bionic are among the organisations that have adopted Salesforce’s Agentforce to boost their productivity.</p>



<p>Adolfo Hernandez, CEO of Capita, said: &#8220;We want to transform Capita’s recruitment process into a fast, seamless and autonomous experience that benefits candidates, our people, and our clients.</p>



<p>“With autonomous agents providing 24/7 support, our goal is to enable candidates to complete the entire recruitment journey within days as opposed to what has historically taken weeks.</p>



<p>Secret Escapes, a curator of luxury travel deals, finds autonomous agents crucial for personalising services to its 60 million European members.</p>



<p>Kate Donaghy, Head of Business Technology at Secret Escapes, added: “Agentforce uses our unified data to automate routine tasks like processing cancellations, updating booking information, or even answering common travel questions about luggage, flight information, and much more—freeing up our customer service agents to handle more complex and last-minute travel needs to better serve our members.”</p>



<p>The UK’s AI readiness is testament to the synergy between government, business, and academia. To maintain its leadership, the UK must sustain its focus on collaboration, skills development, and innovation.&nbsp;</p>



<p><em>(Photo by <a href="https://unsplash.com/@matthewjkwiebe?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Matthew Wiebe</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/generative-ai-use-soars-among-brits-but-is-it-sustainable/"><strong>Generative AI use soars among Brits, but is it sustainable?</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:969px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/salesforce-uk-set-lead-agentic-ai-revolution/">Salesforce: UK set to lead agentic AI revolution</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/salesforce-uk-set-lead-agentic-ai-revolution/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>UK establishes LASR to counter AI security threats</title>
		<link>https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=uk-establishes-lasr-counter-ai-security-threats</link>
					<comments>https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Mon, 25 Nov 2024 11:31:13 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[cyber security]]></category>
		<category><![CDATA[cybersecurity]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[hacking]]></category>
		<category><![CDATA[infosec]]></category>
		<category><![CDATA[nato]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[security]]></category>
		<category><![CDATA[threats]]></category>
		<category><![CDATA[uk]]></category>
		<category><![CDATA[usa]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16550</guid>

					<description><![CDATA[<p>The UK is establishing the Laboratory for AI Security Research (LASR) to help protect Britain and its allies against emerging threats in what officials describe as an &#8220;AI arms race.&#8221; The laboratory – which will receive an initial government funding of £8.22 million – aims to bring together experts from industry, academia, and government to<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/" title="ReadUK establishes LASR to counter AI security threats">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/">UK establishes LASR to counter AI security threats</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The UK is establishing the Laboratory for AI Security Research (LASR) to help protect Britain <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">and its allies</a> against emerging threats in what officials describe as an &#8220;AI arms race.&#8221;</p>



<p>The laboratory – which will receive an initial government funding of £8.22 million – aims to bring together experts from industry, academia, and government to assess AI&#8217;s impact on national security. The announcement comes as part of a broader strategy to strengthen the UK&#8217;s cyber defence capabilities.</p>



<p>Speaking at the NATO Cyber Defence Conference at Lancaster House, the Chancellor of the Duchy of Lancaster said: &#8220;NATO needs to continue to adapt to the world of AI, because as the tech evolves, the threat evolves.</p>



<p>“NATO has stayed relevant over the last seven decades by constantly adapting to new threats. It has navigated the worlds of nuclear proliferation and militant nationalism. The move from cold warfare to drone warfare.”</p>



<p>The Chancellor painted a stark picture of the current cyber security landscape, stating: &#8220;Cyber war is now a daily reality. One where our defences are constantly being tested. The extent of the threat must be matched by the strength of our resolve to combat it and to protect our citizens and systems.&#8221;</p>



<p>The new laboratory will operate under a &#8216;catalytic&#8217; model, designed to attract additional investment and collaboration from industry partners.</p>



<p>Key stakeholders in the new lab include GCHQ, the National Cyber Security Centre, the MOD&#8217;s Defence Science and Technology Laboratory, and prestigious academic institutions such as the University of Oxford and Queen&#8217;s University Belfast.</p>



<p>In a direct warning about Russia&#8217;s activities, the Chancellor declared: &#8220;Be in no doubt: the United Kingdom and others in this room are watching Russia. We know exactly what they are doing, and we are countering their attacks both publicly and behind the scenes.</p>



<p>&#8220;We know from history that appeasing dictators engaged in aggression against their neighbours only encourages them. Britain learned long ago the importance of standing strong in the face of such actions.&#8221;</p>



<p>Reaffirming support for Ukraine, he added, &#8220;Putin is a man who wants destruction, not peace. He is trying to deter our support for Ukraine with his threats. He will not be successful.&#8221;</p>



<p>The new lab follows recent concerns about state actors using AI to bolster existing security threats.</p>



<p>&#8220;Last year, we saw the US for the first time publicly call out a state for using AI to aid its malicious cyber activity,&#8221; the Chancellor noted, referring to North Korea&#8217;s attempts to use AI for malware development and vulnerability scanning.</p>



<p>Stephen Doughty, Minister for Europe, North America and UK Overseas Territories, highlighted the dual nature of AI technology: &#8220;AI has enormous potential. To ensure it remains a force for good in the world, we need to understand its threats and its opportunities.&#8221;</p>



<p>Alongside LASR, the government announced a new £1 million incident response project to enhance collaborative cyber defence capabilities among allies. The laboratory will prioritise collaboration with Five Eyes countries and NATO allies, building on the UK&#8217;s historical strength in computing, dating back to Alan Turing&#8217;s groundbreaking work.</p>



<p>The initiative forms part of the government&#8217;s comprehensive approach to cybersecurity, which includes the upcoming <a href="https://www.gov.uk/government/collections/cyber-security-and-resilience-bill">Cyber Security and Resilience Bill</a> and the recent classification of <a href="https://www.artificialintelligence-news.com/news/uk-secures-6-3b-data-infrastructure-investments/">data centres</a> as critical national infrastructure.</p>



<p><em>(Photo by <a href="https://unsplash.com/@introspectivedsgn?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Erik Mclean</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:969px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/">UK establishes LASR to counter AI security threats</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>OpenAI enhances AI safety with new red teaming methods</title>
		<link>https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=openai-enhances-ai-safety-new-red-teaming-methods</link>
					<comments>https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 22 Nov 2024 15:47:04 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Companies]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[openai]]></category>
		<category><![CDATA[red teaming]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16543</guid>

					<description><![CDATA[<p>A critical part of OpenAI’s safeguarding process is &#8220;red teaming&#8221; — a structured methodology using both human and AI participants to explore potential risks and vulnerabilities in new systems. Historically, OpenAI has engaged in red teaming efforts predominantly through manual testing, which involves individuals probing for weaknesses. This was notably employed during the testing of<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/" title="ReadOpenAI enhances AI safety with new red teaming methods">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/">OpenAI enhances AI safety with new red teaming methods</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>A critical part of OpenAI’s safeguarding process is &#8220;red teaming&#8221; — a structured methodology using both human and AI participants to explore potential risks and vulnerabilities in new systems.</p>



<p>Historically, OpenAI has engaged in red teaming efforts predominantly through manual testing, which involves individuals probing for weaknesses. This was notably employed during the testing of their DALL·E 2 image generation model in early 2022, where external experts were invited to identify potential risks. Since then, OpenAI has expanded and refined its methodologies, incorporating automated and mixed approaches for a more comprehensive risk assessment.</p>



<p>&#8220;We are optimistic that we can use more powerful AI to scale the discovery of model mistakes,&#8221; OpenAI stated. This optimism is rooted in the idea that automated processes can help evaluate models and train them to be safer by recognising patterns and errors on a larger scale.</p>



<p>In their latest push for advancement, OpenAI is sharing two important documents on red teaming — a white paper detailing external engagement strategies and a research study introducing a novel method for automated red teaming. These contributions aim to strengthen the process and outcomes of red teaming, ultimately leading to safer and more responsible AI implementations.</p>



<p>As AI continues to evolve, understanding user experiences and identifying risks such as abuse and misuse are crucial for researchers and developers. Red teaming provides a proactive method for evaluating these risks, especially when supplemented by insights from a range of independent external experts. This approach not only helps establish benchmarks but also facilitates the enhancement of safety evaluations over time.</p>



<h3 class="wp-block-heading">The human touch</h3>



<p>OpenAI has shared four fundamental steps in their white paper, <a href="https://cdn.openai.com/papers/openais-approach-to-external-red-teaming.pdf">&#8220;OpenAI’s Approach to External Red Teaming for AI Models and Systems,&#8221;</a> to design effective red teaming campaigns:</p>



<ol class="wp-block-list">
<li><strong>Composition of red teams:</strong> The selection of team members is based on the objectives of the campaign. This often involves individuals with diverse perspectives, such as expertise in natural sciences, cybersecurity, and regional politics, ensuring assessments cover the necessary breadth.</li>
</ol>



<ol start="2" class="wp-block-list">
<li><strong>Access to model versions:</strong> Clarifying which versions of a model red teamers will access can influence the outcomes. Early-stage models may reveal inherent risks, while more developed versions can help identify gaps in planned safety mitigations.</li>
</ol>



<ol start="3" class="wp-block-list">
<li><strong>Guidance and documentation:</strong> Effective interactions during campaigns rely on clear instructions, suitable interfaces, and structured documentation. This involves describing the models, existing safeguards, testing interfaces, and guidelines for recording results.</li>
</ol>



<ol start="4" class="wp-block-list">
<li><strong>Data synthesis and evaluation:</strong> Post-campaign, the data is assessed to determine if examples align with existing policies or require new behavioural modifications. The assessed data then informs repeatable evaluations for future updates.</li>
</ol>



<p>A recent application of this methodology involved preparing the OpenAI <a href="https://openai.com/index/learning-to-reason-with-llms/">o1 family</a> of models for public use—testing their resistance to potential misuse and evaluating their application across various fields such as real-world attack planning, natural sciences, and AI research.</p>



<h3 class="wp-block-heading">Automated red teaming</h3>



<p>Automated red teaming seeks to identify instances where AI may fail, particularly regarding safety-related issues. This method excels at scale, generating numerous examples of potential errors quickly. However, traditional automated approaches have struggled with producing diverse, successful attack strategies.</p>



<p>OpenAI&#8217;s research introduces <a href="https://cdn.openai.com/papers/diverse-and-effective-red-teaming.pdf">&#8220;Diverse And Effective Red Teaming With Auto-Generated Rewards And Multi-Step Reinforcement Learning,&#8221;</a> a method which encourages greater diversity in attack strategies while maintaining effectiveness.</p>



<p>This method involves using AI to generate different scenarios, such as illicit advice, and training red teaming models to evaluate these scenarios critically. The process rewards diversity and efficacy, promoting more varied and comprehensive safety evaluations.</p>



<p>Despite its benefits, red teaming does have limitations. It captures risks at a specific point in time, which may evolve as AI models develop. Additionally, the red teaming process can inadvertently create information hazards, potentially alerting malicious actors to vulnerabilities not yet widely known. Managing these risks requires stringent protocols and responsible disclosures.</p>



<p>While red teaming continues to be pivotal in risk discovery and evaluation, OpenAI acknowledges the necessity of incorporating broader public perspectives on AI&#8217;s ideal behaviours and policies to ensure the technology aligns with societal values and expectations.</p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/"><strong>EU introduces draft regulatory guidance for AI models</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:959px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/">OpenAI enhances AI safety with new red teaming methods</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>EU introduces draft regulatory guidance for AI models</title>
		<link>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=eu-introduces-draft-regulatory-guidance-for-ai-models</link>
					<comments>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 15 Nov 2024 14:52:05 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ai act]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[eu]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[european union]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[guidance]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Politics]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16496</guid>

					<description><![CDATA[<p>The release of the &#8220;First Draft General-Purpose AI Code of Practice&#8221; marks the EU&#8217;s effort to create comprehensive regulatory guidance for general-purpose AI models. The development of this draft has been a collaborative effort, involving input from diverse sectors including industry, academia, and civil society. The initiative was led by four specialised Working Groups, each<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/" title="ReadEU introduces draft regulatory guidance for AI models">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/">EU introduces draft regulatory guidance for AI models</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The <a href="https://digital-strategy.ec.europa.eu/en/library/first-draft-general-purpose-ai-code-practice-published-written-independent-experts">release</a> of the &#8220;First Draft General-Purpose AI Code of Practice&#8221; marks the EU&#8217;s effort to create comprehensive regulatory guidance for general-purpose AI models.</p>



<p>The development of this draft has been a collaborative effort, involving input from diverse sectors including industry, academia, and civil society. The initiative was led by four specialised Working Groups, each addressing specific aspects of AI governance and risk mitigation:</p>



<ul class="wp-block-list">
<li>Working Group 1: Transparency and copyright-related rules</li>



<li>Working Group 2: Risk identification and assessment for systemic risk</li>



<li>Working Group 3: Technical risk mitigation for systemic risk</li>



<li>Working Group 4: Governance risk mitigation for systemic risk</li>
</ul>



<p>The draft is aligned with existing laws such as the Charter of Fundamental Rights of the European Union. It takes into account international approaches, striving for proportionality to risks, and aims to be future-proof by contemplating rapid technological changes.</p>



<p>Key objectives outlined in the draft include:</p>



<ul class="wp-block-list">
<li>Clarifying compliance methods for providers of general-purpose AI models</li>



<li>Facilitating understanding across the AI value chain, ensuring seamless integration of AI models into downstream products</li>



<li>Ensuring compliance with Union law on copyrights, especially concerning the use of copyrighted material for model training</li>



<li>Continuously assessing and mitigating systemic risks associated with AI models</li>
</ul>



<h3 class="wp-block-heading">Recognising and mitigating systemic risks</h3>



<p>A core feature of the draft is its taxonomy of systemic risks, which includes types, natures, and sources of such risks. The document outlines various threats such as cyber offences, biological risks, loss of control over autonomous AI models, and large-scale disinformation. By acknowledging the continuously evolving nature of AI technology, the draft recognises that this taxonomy will need updates to remain relevant.</p>



<p>As AI models with systemic risks become more common, the draft emphasises the need for robust safety and security frameworks (SSFs). It proposes a hierarchy of measures, sub-measures, and key performance indicators (KPIs) to ensure appropriate risk identification, analysis, and mitigation throughout a model&#8217;s lifecycle.</p>



<p>The draft suggests that providers establish processes to identify and report serious incidents associated with their AI models, offering detailed assessments and corrections as needed. It also encourages collaboration with independent experts for risk assessment, especially for models posing significant systemic risks.</p>



<h3 class="wp-block-heading">Taking a proactive stance to AI regulatory guidance</h3>



<p>The <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">EU AI Act</a>, which came into force on 1 August 2024, mandates that the final version of this Code be ready by 1 May 2025. This initiative underscores the EU&#8217;s proactive stance towards AI regulation, emphasising the need for AI safety, transparency, and accountability.</p>



<p>As the draft continues to evolve, the working groups invite stakeholders to participate actively in refining the document. Their collaborative input will shape a regulatory framework aimed at safeguarding innovation while protecting society from the potential pitfalls of AI technology.</p>



<p>While still in draft form, the EU&#8217;s Code of Practice for general-purpose AI models could set a benchmark for responsible AI development and deployment globally. By addressing key issues such as transparency, risk management, and copyright compliance, the Code aims to create a regulatory environment that fosters innovation, upholds fundamental rights, and ensures a high level of consumer protection.</p>



<p><em>This draft is open for written feedback until 28 November 2024.&nbsp;</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:2239px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/">EU introduces draft regulatory guidance for AI models</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
