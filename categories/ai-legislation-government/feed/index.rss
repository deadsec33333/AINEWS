<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Latest AI Legislation &amp; Government News | AI News</title>
	<atom:link href="https://www.artificialintelligence-news.com/categories/ai-legislation-government/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.artificialintelligence-news.com/categories/ai-legislation-government/</link>
	<description>Artificial Intelligence News</description>
	<lastBuildDate>Thu, 19 Dec 2024 16:21:20 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url>
	<title>Latest AI Legislation &amp; Government News | AI News</title>
	<link>https://www.artificialintelligence-news.com/categories/ai-legislation-government/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>AI governance: Analysing emerging global regulations</title>
		<link>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=ai-governance-analysing-emerging-global-regulations</link>
					<comments>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Thu, 19 Dec 2024 16:21:18 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ai act]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[China]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[eu]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[framework]]></category>
		<category><![CDATA[governance]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Legislation]]></category>
		<category><![CDATA[privacy]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[risks]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[usa]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16742</guid>

					<description><![CDATA[<p>Governments are scrambling to establish regulations to govern AI, citing numerous concerns over data privacy, bias, safety, and more. AI News caught up with Nerijus Šveistys, Senior Legal Counsel at Oxylabs, to understand the state of play when it comes to AI regulation and its potential implications for industries, businesses, and innovation. “The boom of<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/" title="ReadAI governance: Analysing emerging global regulations">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/">AI governance: Analysing emerging global regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Governments are scrambling to establish regulations to govern AI, citing numerous concerns over data privacy, bias, safety, and more.</p>


<div class="wp-block-image">
<figure class="alignright size-full is-resized"><img fetchpriority="high" decoding="async" width="800" height="800" src="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs.jpeg" alt="" class="wp-image-16743" style="width:174px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs.jpeg 800w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-300x300.jpeg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-150x150.jpeg 150w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-768x768.jpeg 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-125x125.jpeg 125w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-200x200.jpeg 200w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-285x285.jpeg 285w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-250x250.jpeg 250w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-100x100.jpeg 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-60x60.jpeg 60w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-400x400.jpeg 400w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/12/Nerijus-Sveistys-oxylabs-600x600.jpeg 600w" sizes="(max-width: 800px) 100vw, 800px" /></figure></div>


<p>AI News caught up with Nerijus Šveistys, Senior Legal Counsel at <a href="https://oxylabs.io/">Oxylabs</a>, to understand the state of play when it comes to AI regulation and its potential implications for industries, businesses, and innovation.</p>



<p>“The boom of the last few years appears to have sparked a push to establish regulatory frameworks for AI governance,” explains Šveistys.</p>



<p>“This is a natural development, as the rise of AI seems to pose issues in data privacy and protection, bias and discrimination, safety, intellectual property, and other legal areas, as well as ethics that need to be addressed.”</p>



<h3 class="wp-block-heading">Regions diverge in regulatory strategy</h3>



<p>The European Union’s <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">AI Act</a> has, unsurprisingly, positioned the region with a strict, centralised approach. The regulation, which came into force this year, is set to be fully effective by 2026.</p>



<p>Šveistys pointed out that the EU has acted relatively swiftly compared to other jurisdictions: “The main difference we can see is the comparative quickness with which the EU has released a uniform regulation to govern the use of all types of AI.”</p>



<p>Meanwhile, other regions have opted for more piecemeal approaches. China, for instance, has been implementing regulations specific to certain AI technologies in a phased-out manner. According to Šveistys, China began regulating AI models as early as 2021.</p>



<p>“In 2021, they introduced regulation on recommendation algorithms, which [had] increased their capabilities in digital advertising. It was followed by regulations <a href="https://www.artificialintelligence-news.com/news/chinas-deepfake-laws-come-into-effect-today/">on deep synthesis models</a> or, in common terms, deepfakes and content generation in 2022,” he said.</p>



<p>“Then, in 2023, regulation on generative AI models was introduced as these models were making a splash in commercial usage.”</p>



<p>The US, in contrast, remains relatively uncoordinated in its approach. Federal-level regulations are yet to be enacted, with efforts mostly emerging at the state level.</p>



<p>“There are proposed regulations at the state level, such as the so-called California AI Act, but even if they come into power, it may still take some time before they do,” Šveistys noted.</p>



<p>This delay in implementing unified AI regulations in the US has raised questions about the extent to which business pushback may be contributing to the slow rollout. Šveistys said that while lobbyist pressure is a known factor, it’s not the only potential reason.</p>



<p>“There was <a href="https://www.artificialintelligence-news.com/news/tech-industry-giants-urge-eu-streamline-ai-regulations/">pushback to the EU AI Act</a>, too, which was nevertheless introduced. Thus, it is not clear whether the delay in the US is only due to lobbyism or other obstacles in the legislation enactment process,” explains Šveistys.</p>



<p>“It might also be because some still see AI as a futuristic concern, not fully appreciating the extent to which it is already a legal issue of today.”</p>



<h3 class="wp-block-heading">Balancing innovation and safety</h3>



<p>Differentiated regulatory approaches could affect the pace of innovation and business competitiveness across regions.</p>



<p>Europe’s regulatory framework, though more stringent, aims to ensure consumer protection and ethical adherence—something that less-regulated environments may lack.</p>



<p>“More rigid regulatory frameworks may impose compliance costs for businesses in the AI field and stifle competitiveness and innovation. On the other hand, they bring the benefits of protecting consumers and adhering to certain ethical norms,” comments Šveistys.</p>



<p>This trade-off is especially pronounced in AI-related sectors such as targeted advertising, where algorithmic bias is increasingly scrutinised.</p>



<p>AI governance often extends beyond laws that specifically target AI, incorporating related legal areas like those governing data collection and privacy. For example, the EU AI Act also regulates the use of AI in physical devices, such as elevators.</p>



<p>&#8220;Additionally, all businesses that collect data for advertisement are potentially affected as AI regulation can also cover algorithmic bias in targeted advertising,&#8221; emphasises Šveistys.</p>



<h3 class="wp-block-heading">Impact on related industries</h3>



<p>One industry that is deeply intertwined with AI developments is web scraping. Typically used for collecting publicly available data, web scraping is undergoing an AI-driven evolution.</p>



<p>&#8220;From data collection, validation, analysis, or overcoming anti-scraping measures, there is a lot of potential for AI to massively improve the efficiency, accuracy, and adaptability of web scraping operations,&#8221; said Šveistys.&nbsp;</p>



<p>However, as AI regulation and related laws tighten, web scraping companies will face greater scrutiny.</p>



<p>“AI regulations may also bring the spotlight on certain areas of law that were always very relevant to the web scraping industry, such as privacy or copyright laws,” Šveistys added.</p>



<p>“At the end of the day, scraping content protected by such laws without proper authorisation could always lead to legal issues, and now so can using AI this way.”</p>



<h3 class="wp-block-heading">Copyright battles and legal precedents</h3>



<p>The implications of AI regulation are also playing out on a broader legal stage, particularly in cases involving generative AI tools.</p>



<p>High-profile <a href="https://www.artificialintelligence-news.com/news/openai-and-microsoft-lawsuit-github-copilot/">lawsuits</a> have been launched against AI giants like OpenAI and its primary backer, Microsoft, by authors, artists, and musicians who claim their copyrighted materials were used to train AI systems without proper permission.</p>



<p>“These cases are pivotal in determining the legal boundaries of using copyrighted material for AI development and establishing legal precedents for protecting intellectual property in the digital age,” said Šveistys.</p>



<p>While these lawsuits could take years to resolve, their outcomes may fundamentally shape the future of AI development. So, what can businesses do now as the regulatory and legal landscape continues to evolve?</p>



<p>“Speaking about the specific cases of using copyrighted material for AI training, businesses should approach this the same way as any web-scraping activity – that is, evaluate the specific data they wish to collect with the help of a legal expert in the field,” recommends Šveistys.</p>



<p>“It is important to recognise that the AI legal landscape is very new and rapidly evolving, with not many precedents in place to refer to as of yet. Hence, continuous monitoring and adaptation of your AI usage are crucial.”</p>



<p>Just this week, the UK Government made headlines with its announcement of a consultation on the use of copyrighted material for training AI models. Under the proposals, tech firms could be permitted to use copyrighted material unless owners have specifically opted out.</p>



<p>Despite the diversity of approaches globally, the AI regulatory push marks a significant moment for technological governance. Whether through the EU’s comprehensive model, China’s step-by-step strategy, or narrower, state-level initiatives like in the US, businesses worldwide must navigate a complex, evolving framework.</p>



<p>The challenge ahead will be striking the right balance between fostering innovation and mitigating risks, ensuring that AI remains a force for good while avoiding potential harms.</p>



<p><em>(Photo by <a href="https://unsplash.com/@nathangbingle?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Nathan Bingle</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:844px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/">AI governance: Analysing emerging global regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/ai-governance-analysing-emerging-global-regulations/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>UK wants to prove AI can modernise public services responsibly</title>
		<link>https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=uk-wants-prove-ai-can-modernise-public-services-responsibly</link>
					<comments>https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Wed, 18 Dec 2024 15:37:46 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[innovation]]></category>
		<category><![CDATA[public sector]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[strategy]]></category>
		<category><![CDATA[uk]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16736</guid>

					<description><![CDATA[<p>The UK Government wants to prove that AI is being deployed responsibly within public services to speed up decision-making, reduce backlogs, and enhance support for citizens. New records, part of the Algorithmic Transparency Recording Standard (ATRS), were published this week to shed light on the AI tools being used and set a benchmark for transparency<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/" title="ReadUK wants to prove AI can modernise public services responsibly">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/">UK wants to prove AI can modernise public services responsibly</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The UK Government wants to prove that AI is being deployed responsibly within public services to speed up decision-making, reduce backlogs, and enhance support for citizens.</p>



<p>New records, part of the Algorithmic Transparency Recording Standard (ATRS), were <a href="https://www.gov.uk/algorithmic-transparency-records">published</a> this week to shed light on the AI tools being used and set a benchmark for transparency and accountability in the integration of technology in public service delivery.</p>



<p>The initiative is part of the government’s broader strategy to embrace technology to improve outcomes, echoing commitments outlined in the <a href="https://www.gov.uk/missions">&#8220;Plan for Change&#8221;</a> to modernise public services and drive economic growth through innovative solutions.</p>



<h3 class="wp-block-heading">The power of AI for modernisation</h3>



<p>Among the published records, the Foreign, Commonwealth and Development Office is leveraging AI to provide faster responses to Britons seeking assistance overseas. Similarly, the Ministry of Justice is utilising algorithms to help researchers gain a deeper understanding of how individuals interact with the justice system, while other departments are deploying AI to enhance job advertisements.</p>



<p>The ATRS aims to document how such algorithmic tools are utilised and ensure their responsible application. By doing so, the government hopes to strengthen public trust in these innovations while encouraging their continued adoption across sectors.</p>



<p>Speaking on the government’s approach, Science Secretary Peter Kyle remarked:&nbsp;&nbsp;</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;Technology has huge potential to transform public services for the better; we will put it to use to cut backlogs, save money, and improve outcomes for citizens across the country.</em></p>



<p><em>Transparency in how and why the public sector is using algorithmic tools is crucial to ensure that they are trusted and effective. That is why we will continue to take bold steps like releasing these records to make sure everyone is clear on how we are applying and trialling technology as we use it to bring public services back from the brink.&#8221;</em></p>
</blockquote>



<p>Specifically, the Department for Business and Trade has highlighted its algorithmic tool designed to predict which companies are likely to export goods internationally.</p>



<p>The AI-driven approach allows officials to target support towards high-growth potential businesses, enabling them to reach global markets faster. Previously reliant on time-consuming manual methods to analyse the more than five million companies registered on Companies House, this advancement ensures better allocation of resources and expedited assistance.</p>



<p>Business Secretary Jonathan Reynolds said:&nbsp;&nbsp;</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;Our Plan for Change will deliver economic growth, and for that to succeed, we need to support companies across the UK to realise their full potential when it comes to exporting around the globe.</em></p>



<p><em>Our use of AI plays a vital and growing role in that mission, allowing high-growth businesses to maximise the export opportunities available to them, while ensuring that we are using taxpayers’ money responsibly and efficiently in delivering economic stability.&#8221;</em></p>
</blockquote>



<h3 class="wp-block-heading">Establishing clear guidelines for AI in public services</h3>



<p>To bolster public trust, new guidelines have been announced to clarify the scope of algorithmic transparency records.</p>



<p>Central government organisations will need to publish a record for any algorithmic tool that interacts directly with citizens or plays a significant role in decision-making about individuals. Limited exceptions, such as those concerning national security, apply.&nbsp;&nbsp;</p>



<p>These records will be published once tools are piloted publicly or have become operational. They will detail the data used to train AI models, the underlying technologies, and the measures implemented to mitigate risks.</p>



<p>Importantly, the records also seek to confirm that – while AI tools are used to accelerate decision-making processes – human oversight remains integral, with trained staff responsible for final decisions.</p>



<p>Dr Antonio Espingardeiro, a member of <a href="https://www.ieee.org/">IEEE</a> and an expert in software and robotics, commented:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;AI has the potential to radically transform the public sector. In recent years, we have seen AI become a credible part of everyday public services. As it becomes more sophisticated, AI can conduct data-heavy tasks traditionally undertaken by humans. It can analyse vast quantities of information and, when coupled with machine learning, search through records and infer patterns or anomalies in data that would otherwise take decades for humans to analyse.</em></p>



<p><em>With this announcement, the UK government has acknowledged AI’s potential and proven that technology investment is essential to improving outcomes and the delivery of vital services. Over time, machine learning and generative AI (GenAI) could bring substantial value to the public system. With increased adoption, we will soon be able to deliver the scalability that the public sector needs and relieve the pressures and workloads placed on staff.&#8221;</em></p>
</blockquote>



<p>Eleanor Watson, also a member of IEEE and an AI ethics engineer affiliated with <a href="https://www.su.org/">Singularity University</a>, added:</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p><em>&#8220;With AI growing more rapidly than ever before, and already being tested and employed in education, healthcare, transportation, finance, data security, and more, the government, tech leaders, and academia should work together to establish standards and regulations for safe and responsible development of AI-based systems. This way, AI can be used to its full potential as indicated with this latest announcement.</em></p>



<p><em>Data privacy is probably the most critical ethical consideration, requiring informed consent, data anonymisation, strict access controls, secure storage, and compliance. New techniques such as homomorphic encryption, zero-knowledge proofs, federated learning, and part-trained models can help models to make use of our personal data in an encrypted form.&#8221;</em></p>
</blockquote>



<p>Transparency remains a key tenet of the UK Government’s AI strategy. This announcement follows a recent statement by Pat McFadden, Chancellor of the Duchy of Lancaster, who affirmed that the benefits of technology – particularly AI – must span both public and private sectors and be used to modernise government.</p>



<p>As the Science Secretary’s department solidifies government efforts to create a &#8220;digital centre,&#8221; it marks a major step forward in boosting the responsible and effective use of AI across the UK’s public sector.</p>



<p>The ATRS records offer a valuable template for how governments worldwide can deploy AI systems to maximise efficiency, grow transparency, and balance the need for innovation with ethical considerations.</p>



<p><em>(Photo by <a href="https://unsplash.com/@shreyasdbz?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Shreyas Sane</a>)</em></p>



<p><strong><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/"><strong>MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</strong></a></strong></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:1082px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/">UK wants to prove AI can modernise public services responsibly</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/uk-wants-prove-ai-can-modernise-public-services-responsibly/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</title>
		<link>https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=mhra-pilots-ai-airlock-accelerate-healthcare-adoption</link>
					<comments>https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Wed, 04 Dec 2024 11:46:32 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Healthcare]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[health]]></category>
		<category><![CDATA[healthcare]]></category>
		<category><![CDATA[medicine]]></category>
		<category><![CDATA[mhra]]></category>
		<category><![CDATA[nhs]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[uk]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16631</guid>

					<description><![CDATA[<p>The Medicines and Healthcare products Regulatory Agency (MHRA) has announced the selection of five healthcare technologies for its ‘AI Airlock’ scheme. AI Airlock aims to refine the process of regulating AI-driven medical devices and help fast-track their safe introduction to the UK’s National Health Service (NHS) and patients in need. The technologies chosen for this<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/" title="ReadMHRA pilots ‘AI Airlock’ to accelerate healthcare adoption">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/">MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The Medicines and Healthcare products Regulatory Agency (<a href="https://www.gov.uk/government/organisations/medicines-and-healthcare-products-regulatory-agency">MHRA</a>) has announced the selection of five healthcare technologies for its ‘AI Airlock’ scheme.</p>



<p>AI Airlock aims to refine the process of regulating AI-driven medical devices and help fast-track their safe introduction to the UK’s National Health Service (NHS) and patients in need.</p>



<p>The technologies chosen for this scheme include solutions targeting cancer and chronic respiratory diseases, as well as advancements in radiology diagnostics. These AI systems promise to revolutionise the accuracy and efficiency of healthcare, potentially driving better diagnostic tools and patient care.</p>



<p>The AI Airlock, as described by the MHRA, is a “sandbox” environment—an experimental framework designed to help manufacturers determine how best to collect real-world evidence to support the regulatory approval of their devices.</p>



<p>Unlike traditional medical devices, AI models continue to evolve through learning, making the establishment of safety and efficacy evidence more complex. The Airlock enables this exploration within a monitored virtual setting, giving developers insight into the practical challenges of regulation while supporting the NHS’s broader adoption of transformative AI technologies.</p>



<h3 class="wp-block-heading">Safely enabling AI healthcare innovation&nbsp;&nbsp;</h3>



<p>Laura Squire, the lead figure in MedTech regulatory reform and Chief Officer at the MHRA, said: “New AI medical devices have the potential to increase the accuracy of healthcare decisions, save time, and improve efficiency—leading to better outcomes for the NHS and patients across all healthcare settings.&nbsp;</p>



<p>“But we need to be confident that AI-powered medical devices introduced into the NHS are safe, stay safe, and perform as intended through their lifetime of use.”</p>



<p>Squire emphasised that the AI Airlock pilot allows collaboration “in partnership with technology specialists, developers and the NHS,” facilitating the exploration of best practices and accelerating safe patient access to innovative solutions.</p>



<p>Government representatives have praised the initiative for its forward-thinking framework.</p>



<p>Karin Smyth, Minister of State for Health, commented: “As part of our 10-Year Health Plan, we’re shifting NHS care from analogue to digital, and this project will help bring the most promising technology to patients.</p>



<p>“AI has the power to revolutionise care by supporting doctors to diagnose diseases, automating time-consuming admin tasks, and reducing hospital admissions by predicting future ill health.”</p>



<p>Science Minister Lord Vallance lauded the AI Airlock pilot as “a great example of government working with businesses to enable them to turn ideas into products that improve lives.” He added, “This shows how good regulation can facilitate emerging technologies for the benefit of the UK and our economy.”</p>



<h3 class="wp-block-heading">Selected technologies&nbsp;&nbsp;</h3>



<p>The deployment of AI-powered medical devices requires meeting stringent criteria to ensure innovation, patient benefits, and regulatory challenge readiness. The five technologies selected for this inaugural pilot offer vital insights into healthcare’s future:&nbsp;</p>



<ol class="wp-block-list">
<li><strong>Lenus Stratify</strong></li>
</ol>



<p>Patients with Chronic Obstructive Pulmonary Disease (COPD) are among those who stand to benefit significantly from AI innovation. Lenus Stratify, developed by Lenus Health, analyses patient data to predict severe lung disease outcomes, reducing unscheduled hospital admissions. The system empowers care providers to adopt earlier interventions, affording patients an improved quality of life while alleviating NHS resource strain.&nbsp;&nbsp;</p>



<ol start="2" class="wp-block-list">
<li><strong>Philips Radiology Reporting Enhancer</strong></li>
</ol>



<p>Philips has integrated AI into existing radiology workflows to enhance the efficiency and accuracy of critical radiology reports. This system uses AI to prepare the “Impression” section of reports, summarising essential diagnostic information for healthcare providers. By automating this process, Philips aims to minimise workload struggles, human errors, and miscommunication, creating a more seamless diagnostic experience.&nbsp;&nbsp;</p>



<ol start="3" class="wp-block-list">
<li><strong>Federated AI Monitoring Service (FAMOS)</strong></li>
</ol>



<p>One recurring AI challenge is the concept of “drift,” when changing real-world conditions impair system performance over time. Newton’s Tree has developed FAMOS to monitor AI models in real time, flagging degradation and enabling rapid corrections. Hospitals, regulators, and software developers can use this tool to ensure algorithms remain high-performing, adapting to evolving circumstances while prioritising patient safety.&nbsp;&nbsp;</p>



<ol start="4" class="wp-block-list">
<li><strong>OncoFlow Personalised Cancer Management</strong></li>
</ol>



<p>Targeting the pressing healthcare challenge of reducing waiting times for cancer treatment, OncoFlow speeds up clinical workflows through its intelligent care pathway platform. Initially applied to breast cancer protocols, the system later aims to expand across other oncology domains. With quicker access to tailored therapies, patients gain increased survival rates amidst mounting NHS pressures.&nbsp;&nbsp;</p>



<ol start="5" class="wp-block-list">
<li><strong>SmartGuideline</strong></li>
</ol>



<p>Developed to simplify complex clinical decision-making processes, SmartGuideline uses large-language AI trained on official NICE medical guidelines. This technology allows clinicians to ask routine questions and receive verified, precise answers, eliminating the ambiguity associated with current AI language models. By integrating this tool, patients benefit from more accurate treatments grounded in up-to-date medical knowledge.&nbsp;&nbsp;</p>



<h3 class="wp-block-heading">Broader implications&nbsp;&nbsp;</h3>



<p>The influence of the AI Airlock extends beyond its current applications. The MHRA expects pilot findings, due in 2025, to inform future medical device regulations and create a clearer path for manufacturers developing AI-enabled technologies.&nbsp;</p>



<p>The evidence derived will contribute to shaping post-Brexit UKCA marking processes, helping manufacturers achieve compliance with higher levels of transparency. By improving regulatory frameworks, the UK could position itself as a global hub for med-tech innovation while ensuring faster access to life-saving tools.</p>



<p>The urgency of these developments was underscored earlier this year in Lord Darzi’s <a href="https://www.gov.uk/government/publications/independent-investigation-of-the-nhs-in-england">review</a> of health and care. The report outlined the “critical state” of the NHS, offering AI interventions as a promising pathway to sustainability. The work on AI Airlock by the MHRA addresses one of the report’s major recommendations for enabling regulatory solutions and “unlocking the AI revolution” for healthcare advancements.</p>



<p>While being selected into the AI Airlock pilot does not indicate regulatory approval, the technologies chosen represent a potential leap forward in applying AI to some of healthcare’s most pressing challenges. The coming years will test the potential of these solutions under regulatory scrutiny.</p>



<p>If successful, the initiative from the MHRA could redefine how pioneering technologies like AI are adopted in <a href="https://www.artificialintelligence-news.com/categories/ai-industries/healthcare/">healthcare</a>, balancing the need for speed, safety, and efficiency. With the NHS under immense pressure from growing demand, AI’s ability to augment clinicians, predict illnesses, and streamline workflows may well be the game-changer the system urgently needs.</p>



<p><em>(Photo by <a href="https://unsplash.com/@nci?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">National Cancer Institute</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/ais-role-in-helping-to-prevent-skin-cancer-through-behaviour-change/"><strong>AI’s role in helping to prevent skin cancer through behaviour change</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:969px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/">MHRA pilots ‘AI Airlock’ to accelerate healthcare adoption</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/mhra-pilots-ai-airlock-accelerate-healthcare-adoption/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>UK establishes LASR to counter AI security threats</title>
		<link>https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=uk-establishes-lasr-counter-ai-security-threats</link>
					<comments>https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Mon, 25 Nov 2024 11:31:13 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[cyber security]]></category>
		<category><![CDATA[cybersecurity]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[hacking]]></category>
		<category><![CDATA[infosec]]></category>
		<category><![CDATA[nato]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[security]]></category>
		<category><![CDATA[threats]]></category>
		<category><![CDATA[uk]]></category>
		<category><![CDATA[usa]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16550</guid>

					<description><![CDATA[<p>The UK is establishing the Laboratory for AI Security Research (LASR) to help protect Britain and its allies against emerging threats in what officials describe as an &#8220;AI arms race.&#8221; The laboratory – which will receive an initial government funding of £8.22 million – aims to bring together experts from industry, academia, and government to<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/" title="ReadUK establishes LASR to counter AI security threats">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/">UK establishes LASR to counter AI security threats</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The UK is establishing the Laboratory for AI Security Research (LASR) to help protect Britain <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">and its allies</a> against emerging threats in what officials describe as an &#8220;AI arms race.&#8221;</p>



<p>The laboratory – which will receive an initial government funding of £8.22 million – aims to bring together experts from industry, academia, and government to assess AI&#8217;s impact on national security. The announcement comes as part of a broader strategy to strengthen the UK&#8217;s cyber defence capabilities.</p>



<p>Speaking at the NATO Cyber Defence Conference at Lancaster House, the Chancellor of the Duchy of Lancaster said: &#8220;NATO needs to continue to adapt to the world of AI, because as the tech evolves, the threat evolves.</p>



<p>“NATO has stayed relevant over the last seven decades by constantly adapting to new threats. It has navigated the worlds of nuclear proliferation and militant nationalism. The move from cold warfare to drone warfare.”</p>



<p>The Chancellor painted a stark picture of the current cyber security landscape, stating: &#8220;Cyber war is now a daily reality. One where our defences are constantly being tested. The extent of the threat must be matched by the strength of our resolve to combat it and to protect our citizens and systems.&#8221;</p>



<p>The new laboratory will operate under a &#8216;catalytic&#8217; model, designed to attract additional investment and collaboration from industry partners.</p>



<p>Key stakeholders in the new lab include GCHQ, the National Cyber Security Centre, the MOD&#8217;s Defence Science and Technology Laboratory, and prestigious academic institutions such as the University of Oxford and Queen&#8217;s University Belfast.</p>



<p>In a direct warning about Russia&#8217;s activities, the Chancellor declared: &#8220;Be in no doubt: the United Kingdom and others in this room are watching Russia. We know exactly what they are doing, and we are countering their attacks both publicly and behind the scenes.</p>



<p>&#8220;We know from history that appeasing dictators engaged in aggression against their neighbours only encourages them. Britain learned long ago the importance of standing strong in the face of such actions.&#8221;</p>



<p>Reaffirming support for Ukraine, he added, &#8220;Putin is a man who wants destruction, not peace. He is trying to deter our support for Ukraine with his threats. He will not be successful.&#8221;</p>



<p>The new lab follows recent concerns about state actors using AI to bolster existing security threats.</p>



<p>&#8220;Last year, we saw the US for the first time publicly call out a state for using AI to aid its malicious cyber activity,&#8221; the Chancellor noted, referring to North Korea&#8217;s attempts to use AI for malware development and vulnerability scanning.</p>



<p>Stephen Doughty, Minister for Europe, North America and UK Overseas Territories, highlighted the dual nature of AI technology: &#8220;AI has enormous potential. To ensure it remains a force for good in the world, we need to understand its threats and its opportunities.&#8221;</p>



<p>Alongside LASR, the government announced a new £1 million incident response project to enhance collaborative cyber defence capabilities among allies. The laboratory will prioritise collaboration with Five Eyes countries and NATO allies, building on the UK&#8217;s historical strength in computing, dating back to Alan Turing&#8217;s groundbreaking work.</p>



<p>The initiative forms part of the government&#8217;s comprehensive approach to cybersecurity, which includes the upcoming <a href="https://www.gov.uk/government/collections/cyber-security-and-resilience-bill">Cyber Security and Resilience Bill</a> and the recent classification of <a href="https://www.artificialintelligence-news.com/news/uk-secures-6-3b-data-infrastructure-investments/">data centres</a> as critical national infrastructure.</p>



<p><em>(Photo by <a href="https://unsplash.com/@introspectivedsgn?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Erik Mclean</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:969px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/">UK establishes LASR to counter AI security threats</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Preparing today for tomorrow&#8217;s AI regulations</title>
		<link>https://www.artificialintelligence-news.com/news/preparing-today-for-tomorrows-ai-regulations/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=preparing-today-for-tomorrows-ai-regulations</link>
					<comments>https://www.artificialintelligence-news.com/news/preparing-today-for-tomorrows-ai-regulations/#respond</comments>
		
		<dc:creator><![CDATA[AI News]]></dc:creator>
		<pubDate>Wed, 20 Nov 2024 15:41:58 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16522</guid>

					<description><![CDATA[<p>AI is rapidly becoming ubiquitous across business systems and IT ecosystems, with adoption and development racing faster than anyone could have expected. Today it seems that everywhere we turn, software engineers are building custom models and integrating AI into their products, as business leaders incorporate AI-powered solutions in their working environments. However, uncertainty about the<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/preparing-today-for-tomorrows-ai-regulations/" title="ReadPreparing today for tomorrow&#8217;s AI regulations">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/preparing-today-for-tomorrows-ai-regulations/">Preparing today for tomorrow&#8217;s AI regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>AI is rapidly becoming ubiquitous across business systems and IT ecosystems, with adoption and development racing faster than anyone could have expected. Today it seems that everywhere we turn, software engineers are building custom models and integrating AI into their products, as business leaders incorporate AI-powered solutions in their working environments.</p>



<p>However, uncertainty about the best way to implement AI is stopping some companies from taking action. Boston Consulting Group&#8217;s latest Digital Acceleration Index (DAI), a global survey of 2,700 executives, revealed that<a href="https://www.bcg.com/publications/2023/how-to-prepare-for-ai-regulation"> only 28% say</a> their organisation is fully prepared for new AI regulation.</p>



<p>Their uncertainty is exacerbated by AI regulations arriving thick and fast: the<a href="https://www.artificialintelligence-news.com/news/balancing-innovation-trust-experts-assess-eu-ai-act/"> EU AI act is on the way</a>; Argentina released a draft AI plan; Canada has the AI and Data Act; China has enacted a slew of AI regulations; and the G7 nations launched the &#8220;Hiroshima AI process.&#8221; Guidelines abound, with the OECD developing AI principles, the UN proposing a new UN AI advisory body, and the Biden administration releasing a blueprint for an AI Bill of Rights (although that could quickly change with the second Trump administration).</p>



<p>Legislation is also coming in individual US states, and is appearing in many industry frameworks. To date, 21 states have enacted laws to regulate AI use in some manner, including the Colourado AI Act, and clauses in California&#8217;s CCPA, plus a further 14 states have legislation awaiting approval.</p>



<p>Meanwhile, there are loud voices on both sides of the AI regulation debate. A new survey from SolarWinds shows<a href="https://www.artificialintelligence-news.com/news/solarwinds-it-professionals-stronger-ai-regulation/"> 88% of IT professionals advocate</a> for stronger regulation, and separate research reveals that<a href="https://www.artificialintelligence-news.com/news/uk-announces-over-100m-support-agile-ai-regulation/"> 91% of British people</a> want the government to do more to hold businesses accountable for their AI systems. On the other hand, the leaders of over 50 tech companies<a href="https://www.artificialintelligence-news.com/news/tech-industry-giants-urge-eu-streamline-ai-regulations/"> recently wrote an open letter</a> calling for urgent reform of the EU&#8217;s heavy AI regulations, arguing that they stifle innovation.</p>



<p>It&#8217;s certainly a tricky period for business leaders and software developers, as regulators scramble to catch up with tech. Of course you want to take advantage of the benefits AI can provide, you can do so in a way that sets you up for compliance with whatever regulatory requirements are coming, and don&#8217;t handicap your AI use unnecessarily while your rivals speed ahead.</p>



<p>We don&#8217;t have a crystal ball, so we can&#8217;t predict the future. But we can share some best practices for setting up systems and procedures that will prepare the ground for AI regulatory compliance.</p>



<h2 class="wp-block-heading"><strong>Map out AI usage in your wider ecosystem</strong></h2>



<p>You can&#8217;t manage your team&#8217;s AI use unless you know about it, but that alone can be a significant challenge. Shadow IT is already the scourge of cybersecurity teams: Employees sign up for SaaS tools without the knowledge of IT departments, leaving an unknown number of solutions and platforms with access to business data and/or systems.</p>



<p>Now security teams also have to grapple with shadow AI. Many apps, chatbots, and other tools incorporate AI, machine learning (ML), or natural language programming (NLP), without such solutions necessarily being obvious AI solutions. When employees log into these solutions without official approval, they bring AI into your systems without your knowledge.</p>



<p>As Opice Blum&#8217;s data privacy expert<a href="https://iapp.org/news/a/establishing-governance-for-ai-systems"> Henrique Fabretti Moraes explained</a>, &#8220;Mapping the tools in use – or those intended for use – is crucial for understanding and fine-tuning acceptable use policies and potential mitigation measures to decrease the risks involved in their utilisation.&#8221;</p>



<p>Some regulations hold you responsible for AI use by vendors. To take full control of the situation, you need to map all the AI in your, and your partner organisations&#8217; environments. In this regard, using a tool like<a href="https://www.harmonic.security/blog-posts/how-to-detect-and-mitigate-shadow-ai-in-your-organisation"> Harmonic</a> can be instrumental in detecting AI use across the supply chain.</p>



<h2 class="wp-block-heading"><strong>Verify data governance</strong></h2>



<p>Data privacy and security are core concerns for all AI regulations, both those already in place and those on the brink of approval.</p>



<p>Your AI use already needs to comply with existing privacy laws like GDPR and CCPR, which require you to know what data your AI can access and what it does with the data, and for you to demonstrate guardrails to protect the data AI uses.</p>



<p>To ensure compliance, you need to put robust data governance rules into place in your organisation, managed by a defined team, and backed up by regular audits. Your policies should include due diligence to evaluate data security and sources of all your tools, including those that use AI, to identify areas of potential bias and privacy risk.</p>



<p>&#8220;It is incumbent on organisations to take proactive measures by enhancing data hygiene, enforcing robust AI ethics and assembling the right teams to lead these efforts,&#8221;<a href="https://www.artificialintelligence-news.com/news/uk-announces-over-100m-support-agile-ai-regulation/"> said Rob Johnson</a>, VP and Global Head of Solutions Engineering at SolarWinds. &#8220;This proactive stance not only helps with compliance with evolving regulations but also maximises the potential of AI.&#8221;</p>



<h2 class="wp-block-heading"><strong>Establish continuous monitoring for your AI systems</strong></h2>



<p>Effective monitoring is crucial for managing any area of your business. When it comes to AI, as with other areas of cybersecurity, you need continuous monitoring to ensure that you know what your AI tools are doing, how they are behaving, and what data they are accessing. You also need to audit them regularly to keep on top of AI use in your organisation.</p>



<p>&#8220;The idea of using AI to monitor and regulate other AI systems is a crucial development in ensuring these systems are both effective and ethical,&#8221;<a href="https://www.informationweek.com/machine-learning-ai/how-to-monitor-ai-with-ai"> said Cache Merrill</a>, founder of software development company Zibtek. &#8220;Currently, techniques like machine learning models that predict other models&#8217; behaviours (meta-models) are employed to monitor AI. The systems analyse patterns and outputs of operational AI to detect anomalies, biases or potential failures before they become critical.&#8221;</p>



<p>Cyber GRC automation platform<a href="https://cypago.com/"> Cypago</a> allows you to run continuous monitoring and regulatory audit evidence collection in the background. The no-code automation allows you to set custom workflow capabilities without technical expertise, so alerts and mitigation actions are triggered instantly according to the controls and thresholds you set up.</p>



<p>Cypago can connect with your various digital platforms, synchronise with virtually any regulatory framework, and turn all relevant controls into automated workflows. Once your integrations and regulatory frameworks are set up, creating custom workflows on the platform is as simple as uploading a spreadsheet.</p>



<h2 class="wp-block-heading"><strong>Use risk assessments as your guidelines</strong></h2>



<p>It&#8217;s vital to know which of your AI tools are high risk, medium risk, and low risk – for compliance with external regulations, for internal business risk management, and for improving software development workflows. High risk use cases will need more safeguards and evaluation before deployment.</p>



<p>&#8220;While AI risk management can be started at any point in the project development,&#8221; Ayesha Gulley, an AI policy expert from Holistic AI,<a href="https://www.holisticai.com/blog/need-for-risk-management-in-ai"> said</a>. &#8220;Implementing a risk management framework sooner than later can help enterprises increase trust and scale with confidence.&#8221;</p>



<p>When you know the risks posed by different AI solutions, you can choose the level of access you&#8217;ll grant them to data and critical business systems.</p>



<p>In terms of regulations, the EU AI Act already distinguishes between AI systems with different risk levels, and NIST recommends assessing AI tools based on trustworthiness, social impact, and how humans interact with the system.</p>



<h2 class="wp-block-heading"><strong>Proactively set AI ethics governance</strong></h2>



<p>You don&#8217;t need to wait for AI regulations to set up ethical AI policies. Allocate responsibility for ethical AI considerations, put together teams, and draw up policies for ethical AI use that include cybersecurity, model validation, transparency, data privacy, and incident reporting.</p>



<p>Plenty of existing frameworks like NIST&#8217;s AI RMF and ISO/IEC 42001 recommend AI best practices that you can incorporate into your policies.</p>



<p>&#8220;Regulating AI is both necessary and inevitable to ensure ethical and responsible use. While this may introduce complexities, it need not hinder innovation,&#8221;<a href="https://minutehack.com/opinions/as-ai-regulation-looms-what-does-it-mean-for-innovation"> said Arik Solomon</a>, CEO and co-founder of Cypago. &#8220;By integrating compliance into their internal frameworks and developing policies and processes aligned with regulatory principles, companies in regulated industries can continue to grow and innovate effectively.&#8221;</p>



<p>Companies that can demonstrate a proactive approach to ethical AI will be better positioned for compliance. AI regulations aim to ensure transparency and data privacy, so if your goals align with these principles, you&#8217;ll be more likely to have policies in place that comply with future regulation. The<a href="https://fairnow.ai/"> FairNow</a> platform can help with this process, with tools for managing AI governance, bias checks, and risk assessments in a single location.</p>



<h2 class="wp-block-heading"><strong>Don&#8217;t let fear of AI regulation hold you back</strong></h2>



<p>AI regulations are still evolving and emerging, creating uncertainty for businesses and developers. But don&#8217;t let the fluid situation stop you from benefiting from AI. By proactively implementing policies, workflows, and tools that align with the principles of data privacy, transparency, and ethical use, you can prepare for AI regulations and take advantage of AI-powered possibilities.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/preparing-today-for-tomorrows-ai-regulations/">Preparing today for tomorrow&#8217;s AI regulations</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/preparing-today-for-tomorrows-ai-regulations/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>EU introduces draft regulatory guidance for AI models</title>
		<link>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=eu-introduces-draft-regulatory-guidance-for-ai-models</link>
					<comments>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 15 Nov 2024 14:52:05 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[ai act]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[eu]]></category>
		<category><![CDATA[europe]]></category>
		<category><![CDATA[european union]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[guidance]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Politics]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16496</guid>

					<description><![CDATA[<p>The release of the &#8220;First Draft General-Purpose AI Code of Practice&#8221; marks the EU&#8217;s effort to create comprehensive regulatory guidance for general-purpose AI models. The development of this draft has been a collaborative effort, involving input from diverse sectors including industry, academia, and civil society. The initiative was led by four specialised Working Groups, each<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/" title="ReadEU introduces draft regulatory guidance for AI models">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/">EU introduces draft regulatory guidance for AI models</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The <a href="https://digital-strategy.ec.europa.eu/en/library/first-draft-general-purpose-ai-code-practice-published-written-independent-experts">release</a> of the &#8220;First Draft General-Purpose AI Code of Practice&#8221; marks the EU&#8217;s effort to create comprehensive regulatory guidance for general-purpose AI models.</p>



<p>The development of this draft has been a collaborative effort, involving input from diverse sectors including industry, academia, and civil society. The initiative was led by four specialised Working Groups, each addressing specific aspects of AI governance and risk mitigation:</p>



<ul class="wp-block-list">
<li>Working Group 1: Transparency and copyright-related rules</li>



<li>Working Group 2: Risk identification and assessment for systemic risk</li>



<li>Working Group 3: Technical risk mitigation for systemic risk</li>



<li>Working Group 4: Governance risk mitigation for systemic risk</li>
</ul>



<p>The draft is aligned with existing laws such as the Charter of Fundamental Rights of the European Union. It takes into account international approaches, striving for proportionality to risks, and aims to be future-proof by contemplating rapid technological changes.</p>



<p>Key objectives outlined in the draft include:</p>



<ul class="wp-block-list">
<li>Clarifying compliance methods for providers of general-purpose AI models</li>



<li>Facilitating understanding across the AI value chain, ensuring seamless integration of AI models into downstream products</li>



<li>Ensuring compliance with Union law on copyrights, especially concerning the use of copyrighted material for model training</li>



<li>Continuously assessing and mitigating systemic risks associated with AI models</li>
</ul>



<h3 class="wp-block-heading">Recognising and mitigating systemic risks</h3>



<p>A core feature of the draft is its taxonomy of systemic risks, which includes types, natures, and sources of such risks. The document outlines various threats such as cyber offences, biological risks, loss of control over autonomous AI models, and large-scale disinformation. By acknowledging the continuously evolving nature of AI technology, the draft recognises that this taxonomy will need updates to remain relevant.</p>



<p>As AI models with systemic risks become more common, the draft emphasises the need for robust safety and security frameworks (SSFs). It proposes a hierarchy of measures, sub-measures, and key performance indicators (KPIs) to ensure appropriate risk identification, analysis, and mitigation throughout a model&#8217;s lifecycle.</p>



<p>The draft suggests that providers establish processes to identify and report serious incidents associated with their AI models, offering detailed assessments and corrections as needed. It also encourages collaboration with independent experts for risk assessment, especially for models posing significant systemic risks.</p>



<h3 class="wp-block-heading">Taking a proactive stance to AI regulatory guidance</h3>



<p>The <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">EU AI Act</a>, which came into force on 1 August 2024, mandates that the final version of this Code be ready by 1 May 2025. This initiative underscores the EU&#8217;s proactive stance towards AI regulation, emphasising the need for AI safety, transparency, and accountability.</p>



<p>As the draft continues to evolve, the working groups invite stakeholders to participate actively in refining the document. Their collaborative input will shape a regulatory framework aimed at safeguarding innovation while protecting society from the potential pitfalls of AI technology.</p>



<p>While still in draft form, the EU&#8217;s Code of Practice for general-purpose AI models could set a benchmark for responsible AI development and deployment globally. By addressing key issues such as transparency, risk management, and copyright compliance, the Code aims to create a regulatory environment that fosters innovation, upholds fundamental rights, and ensures a high level of consumer protection.</p>



<p><em>This draft is open for written feedback until 28 November 2024.&nbsp;</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:2239px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/">EU introduces draft regulatory guidance for AI models</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Understanding AI&#8217;s impact on the workforce</title>
		<link>https://www.artificialintelligence-news.com/news/understanding-ai-impact-on-the-workforce/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=understanding-ai-impact-on-the-workforce</link>
					<comments>https://www.artificialintelligence-news.com/news/understanding-ai-impact-on-the-workforce/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 08 Nov 2024 10:11:03 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[ethics]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[labor]]></category>
		<category><![CDATA[labour]]></category>
		<category><![CDATA[Legislation]]></category>
		<category><![CDATA[report]]></category>
		<category><![CDATA[research]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[tony blair institute]]></category>
		<category><![CDATA[workforce]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16459</guid>

					<description><![CDATA[<p>The Tony Blair Institute (TBI) has examined AI&#8217;s impact on the workforce. The report outlines AI’s potential to reshape work environments, boost productivity, and create opportunities—while warning of potential challenges ahead. &#8220;Technology has a long history of profoundly reshaping the world of work,&#8221; the report begins. From the agricultural revolution to the digital age, each<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/understanding-ai-impact-on-the-workforce/" title="ReadUnderstanding AI&#8217;s impact on the workforce">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/understanding-ai-impact-on-the-workforce/">Understanding AI&#8217;s impact on the workforce</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The <a href="https://institute.global/">Tony Blair Institute</a> (TBI) has examined AI&#8217;s impact on the workforce. The report outlines AI’s potential to reshape work environments, boost productivity, and create opportunities—while warning of potential challenges ahead.</p>



<p>&#8220;Technology has a long history of profoundly reshaping the world of work,&#8221; the report begins.</p>



<p>From the agricultural revolution to the digital age, each wave of innovation has redefined labour markets. Today, AI presents a seismic shift, advancing rapidly and prompting policymakers to prepare for change.</p>



<h3 class="wp-block-heading">Economic opportunities</h3>



<p>The TBI report estimates that AI, when fully adopted by UK firms, could significantly increase productivity. It suggests that AI could save &#8220;almost a quarter of private-sector workforce time,&#8221; equivalent to the annual output of 6 million workers.</p>



<p>Most of these time savings are expected to stem from AI-enabled software performing cognitive tasks such as data analysis and routine administrative operations.</p>



<p>The report identifies sectors reliant on routine cognitive tasks, such as banking and finance, as those with significant exposure to AI. However, sectors like skilled trades or construction – which involve complex manual tasks – are likely to see less direct impact.</p>



<p>While AI can result in initial job losses, it also has the potential to create new demand by fostering economic growth and new industries.&nbsp;</p>



<p>The report expects these job losses can be balanced by new job creation. Over the years, technology has historically spurred new employment opportunities, as innovation leads to the development of new products and services.</p>



<h3 class="wp-block-heading">Shaping future generations</h3>



<p>AI’s potential extends into education, where it could assist both teachers and students.</p>



<p>The report suggests that AI could help &#8220;raise educational attainment by around six percent&#8221; on average. By personalising and supporting learning, AI has the potential to equalise access to opportunities and improve the quality of the workforce over time.</p>



<h3 class="wp-block-heading">Health and wellbeing</h3>



<p>Beyond education, AI offers potential benefits in healthcare, supporting a healthier workforce and reducing welfare costs.</p>



<p>The report highlights AI’s role in speeding medical research, enabling preventive healthcare, and helping those with disabilities re-enter the workforce.</p>



<h3 class="wp-block-heading">Workplace transformation</h3>



<p>The report acknowledges potential workplace challenges, such as increased monitoring and stress from AI tools. It stresses the importance of managing these technologies thoughtfully to &#8220;deliver a more engaging, inclusive and safe working environment.&#8221;</p>



<p>To mitigate potential disruption, the TBI outlines recommendations. These include upgrading labour-market infrastructure and utilising AI for job matching.</p>



<p>The report suggests creating an &#8220;Early Awareness and Opportunity System&#8221; to help workers understand the impact of AI on their jobs and provide advice on career paths.</p>



<h3 class="wp-block-heading">Preparing for an AI-powered future</h3>



<p>In light of the uncertainties surrounding AI’s impact on the workforce, the TBI urges policy changes to maximise benefits. Recommendations include incentivising AI adoption across industries, developing AI-pathfinder programmes, and creating challenge prizes to address public-sector labour shortages.</p>



<p>The report concludes that while AI presents risks, the potential gains are too significant to ignore.</p>



<p><a href="https://www.artificialintelligence-news.com/categories/ai-legislation-government/">Policymakers</a> are encouraged to adopt a &#8220;pro-innovation&#8221; stance while being attuned to the risks, fostering an economy that is dynamic and resilient.</p>



<p><em>(Photo by <a href="https://unsplash.com/@mimithian?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Mimi Thian</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic urges AI regulation to avoid catastrophes</strong></a></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/understanding-ai-impact-on-the-workforce/">Understanding AI&#8217;s impact on the workforce</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/understanding-ai-impact-on-the-workforce/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>AI hallucinations gone wrong as Alaska uses fake stats in policy</title>
		<link>https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy</link>
					<comments>https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/#respond</comments>
		
		<dc:creator><![CDATA[Muhammad Zulhusni]]></dc:creator>
		<pubDate>Tue, 05 Nov 2024 16:12:42 +0000</pubDate>
				<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Chatbots]]></category>
		<category><![CDATA[Industries]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[policy]]></category>
		<category><![CDATA[research]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16432</guid>

					<description><![CDATA[<p>The combination of artificial intelligence and policymaking can occasionally have unforeseen repercussions, as seen recently in Alaska. In an unusual turn of events, Alaska legislators reportedly used AI-generated citations that were inaccurate to justify a proposed policy banning cellphones in schools. As reported by /The Alaska Beacon/, Alaska’s Department of Education and Early Development (DEED)<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/" title="ReadAI hallucinations gone wrong as Alaska uses fake stats in policy">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/">AI hallucinations gone wrong as Alaska uses fake stats in policy</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The combination of artificial intelligence and policymaking can occasionally have unforeseen repercussions, as seen recently in Alaska.</p>



<p>In an unusual turn of events, Alaska legislators reportedly used AI-generated citations that were inaccurate to justify a proposed policy banning cellphones in schools. As reported by /The Alaska Beacon/, Alaska’s Department of Education and Early Development (DEED) presented a policy draft containing references to academic studies that simply did not exist.</p>



<p>The situation arose when Alaska’s Education Commissioner, Deena Bishop, used generative AI to draft the cellphone policy. The document produced by the AI included supposed scholarly references that were neither verified nor accurate, yet the document did not disclose the use of AI in its preparation. Some of the AI-generated content reached the Alaska State Board of Education and Early Development before it could be reviewed, potentially influencing board discussions.</p>



<p>Commissioner Bishop later claimed that AI was used only to “create citations” for an initial draft and asserted that she corrected the errors before the meeting by sending updated citations to board members. However, AI “hallucinations”—fabricated information generated when AI attempts to create plausible yet unverified content—were still present in the final document that was voted on by the board.</p>



<p>The final resolution, published on DEED’s website, directs the department to establish a model policy for cellphone restrictions in schools. Unfortunately, the document included six citations, four of which seemed to be from respected scientific journals. However, the references were entirely made up, with URLs that led to unrelated content. The incident shows the risks of using AI-generated data without proper human verification, especially when making policy rulings.</p>



<p>Alaska’s case is not one of a kind. AI hallucinations are increasingly common in a variety of professional sectors. For example, some legal professionals have faced consequences for using AI-generated, fictitious case citations in court. Similarly, academic papers created using AI have included distorted data and fake sources, presenting serious credibility concerns. When left unchecked, generative AI algorithms, which are meant to produce content based on patterns rather than factual accuracy, can easily produce misleading citations.</p>



<p>The reliance on AI-generated data in policymaking, particularly in education, carries significant risks. When policies are developed based on fabricated information, they may misallocate resources and potentially harm students. For instance, a policy restricting cellphone use based on fabricated data may divert attention from more effective, evidence-based interventions that could genuinely benefit students.</p>



<p>Furthermore, using unverified AI data can erode public trust in both the policymaking process and AI technology itself. Such incidents underscore the importance of fact-checking, transparency, and caution when using AI in sensitive decision-making areas, especially in education, where impact on students can be profound.</p>



<p>Alaska officials attempted to downplay the situation, referring to the fabricated citations as “placeholders” intended for later correction. However, the document with the “placeholders” was still presented to the board and used as the basis for a vote, underscoring the need for rigorous oversight when using AI.</p>



<p><em>(Photo by <a href="https://unsplash.com/@hartonocreativestudio?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Hartono Creative Studio</a>)</em></p>



<p><strong>See also: <a target="_blank" href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/" rel="noreferrer noopener">Anthropic urges AI regulation to avoid catastrophes</a></strong></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/">AI hallucinations gone wrong as Alaska uses fake stats in policy</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/ai-hallucinations-gone-wrong-as-alaska-uses-fake-stats-in-policy/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Anthropic urges AI regulation to avoid catastrophes</title>
		<link>https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=anthropic-urges-ai-regulation-avoid-catastrophes</link>
					<comments>https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 01 Nov 2024 16:46:42 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Companies]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[anthropic]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[law]]></category>
		<category><![CDATA[legal]]></category>
		<category><![CDATA[Legislation]]></category>
		<category><![CDATA[policy]]></category>
		<category><![CDATA[Politics]]></category>
		<category><![CDATA[regulation]]></category>
		<category><![CDATA[risks]]></category>
		<category><![CDATA[rsp]]></category>
		<category><![CDATA[safety]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16415</guid>

					<description><![CDATA[<p>Anthropic has flagged the potential risks of AI systems and calls for well-structured regulation to avoid potential catastrophes. The organisation argues that targeted regulation is essential to harness AI&#8217;s benefits while mitigating its dangers. As AI systems evolve in capabilities such as mathematics, reasoning, and coding, their potential misuse in areas like cybersecurity or even<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/" title="ReadAnthropic urges AI regulation to avoid catastrophes">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/">Anthropic urges AI regulation to avoid catastrophes</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p><a href="https://www.anthropic.com/">Anthropic</a> has flagged the potential risks of AI systems and calls for well-structured regulation to avoid potential catastrophes. The organisation argues that targeted regulation is essential to harness AI&#8217;s benefits while mitigating its dangers.</p>



<p>As AI systems evolve in capabilities such as mathematics, reasoning, and coding, their potential misuse in areas like cybersecurity or even biological and chemical disciplines significantly increases.</p>



<p>Anthropic warns the next 18 months are critical for policymakers to act, as the window for proactive prevention is narrowing. Notably, Anthropic&#8217;s Frontier Red Team highlights how current models can already contribute to various cyber offense-related tasks and expects future models to be even more effective.</p>



<p>Of particular concern is the potential for AI systems to exacerbate chemical, biological, radiological, and nuclear (CBRN) misuse. The UK AI Safety Institute <a href="https://www.aisi.gov.uk/work/advanced-ai-evaluations-may-update">found</a> that several AI models can now match PhD-level human expertise in providing responses to science-related inquiries.</p>



<p>In addressing these risks, Anthropic has detailed its <a href="https://assets.anthropic.com/m/24a47b00f10301cd/original/Anthropic-Responsible-Scaling-Policy-2024-10-15.pdf">Responsible Scaling Policy</a> (RSP) that was released in September 2023 as a robust countermeasure. RSP mandates an increase in safety and security measures corresponding to the sophistication of AI capabilities.</p>



<p>The RSP framework is designed to be adaptive and iterative, with regular assessments of AI models allowing for timely refinement of safety protocols. Anthropic says that it’s committed to maintaining and enhancing safety spans various team expansions, particularly in security, interpretability, and trust sectors, ensuring readiness for the rigorous safety standards set by its RSP.</p>



<p>Anthropic believes the widespread adoption of RSPs across the AI industry, while primarily voluntary, is essential for addressing AI risks.</p>



<p>Transparent, effective regulation is crucial to reassure society of AI companies&#8217; adherence to promises of safety. Regulatory frameworks, however, must be strategic, incentivising sound safety practices without imposing unnecessary burdens.</p>



<p>Anthropic envisions regulations that are clear, focused, and adaptive to evolving technological landscapes, arguing that these are vital in achieving a balance between risk mitigation and fostering innovation.</p>



<p>In the US, Anthropic suggests that federal <a href="https://www.artificialintelligence-news.com/categories/ai-legislation-government/">legislation</a> could be the ultimate answer to AI risk regulation—though state-driven initiatives might need to step in if federal action lags. Legislative frameworks developed by countries worldwide should allow for standardisation and mutual recognition to support a <a href="https://www.artificialintelligence-news.com/news/un-passes-first-global-ai-resolution/">global AI safety</a> agenda, minimising the cost of regulatory adherence across different regions.</p>



<p>Furthermore, Anthropic addresses scepticism towards imposing regulations—highlighting that overly broad use-case-focused regulations would be inefficient for general AI systems, which have diverse applications. Instead, regulations should target fundamental properties and safety measures of AI models.&nbsp;</p>



<p>While covering broad risks, Anthropic acknowledges that some immediate threats – like deepfakes – aren&#8217;t the focus of their current proposals since other initiatives are tackling these nearer-term issues.</p>



<p>Ultimately, Anthropic stresses the importance of instituting regulations that spur innovation rather than stifle it. The initial compliance burden, though inevitable, can be minimised through flexible and carefully-designed <a href="https://www.artificialintelligence-news.com/news/uk-and-us-sign-pact-develop-ai-safety-tests/">safety tests</a>. Proper regulation can even help safeguard both national interests and private sector innovation by securing intellectual property against threats internally and externally.</p>



<p>By focusing on empirically measured risks, Anthropic plans for a regulatory landscape that neither biases against nor favours open or closed-source models. The objective remains clear: to manage the significant risks of frontier AI models with rigorous but adaptable regulation.</p>



<p><em>(Image Credit: <a href="https://www.anthropic.com/">Anthropic</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/"><strong>President Biden issues first National Security Memorandum on AI</strong></a></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/">Anthropic urges AI regulation to avoid catastrophes</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>President Biden issues first National Security Memorandum on AI</title>
		<link>https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=president-biden-issues-first-national-security-memorandum-ai</link>
					<comments>https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/#respond</comments>
		
		<dc:creator><![CDATA[Ryan Daws]]></dc:creator>
		<pubDate>Fri, 25 Oct 2024 14:45:42 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Ethics & Society]]></category>
		<category><![CDATA[Legislation & Government]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[biden]]></category>
		<category><![CDATA[framework]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[memorandum]]></category>
		<category><![CDATA[nsm]]></category>
		<category><![CDATA[security]]></category>
		<category><![CDATA[usa]]></category>
		<guid isPermaLink="false">https://www.artificialintelligence-news.com/?p=16393</guid>

					<description><![CDATA[<p>President Biden has issued the US&#8217; first-ever National Security Memorandum (NSM) on AI, addressing how the nation approaches the technology from a security perspective. The memorandum, which builds upon Biden&#8217;s earlier executive order on AI, is founded on the premise that cutting-edge AI developments will substantially impact national security and foreign policy in the immediate<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/" title="ReadPresident Biden issues first National Security Memorandum on AI">... Read more &#187;</a></p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">President Biden issues first National Security Memorandum on AI</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>President Biden has <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/">issued</a> the US&#8217; first-ever National Security Memorandum (NSM) on AI, addressing how the nation approaches the technology from a security perspective.</p>



<p>The memorandum, which builds upon Biden&#8217;s earlier executive order on AI, is founded on the premise that cutting-edge AI developments will substantially impact national security and foreign policy in the immediate future.</p>



<p>Security experts suggest the implications are already being felt. &#8220;AI already has implications for national security, as we know that more and more attackers are using AI to create higher volume and more complex attacks, especially in the social engineering and misinformation fronts,&#8221; says Melissa Ruzzi, Director of AI at <a href="https://appomni.com/">AppOmni</a>.</p>



<p>At its core, the NSM outlines three primary objectives: establishing US leadership in safe AI development, leveraging AI technologies for national security, and fostering international governance frameworks.</p>



<p>&#8220;Our competitors want to upend US AI leadership and have employed economic and technological espionage in efforts to steal US technology,&#8221; the memorandum states, elevating the protection of American AI innovations to a &#8220;top-tier intelligence priority.&#8221;</p>



<p>The document formally designates the AI Safety Institute as the primary governmental point of contact for the AI industry. This institute will be staffed with technical experts and will maintain close partnerships with national security agencies, including the intelligence community, Department of Defence, and Department of Energy.</p>



<p>&#8220;The actions listed in the memo are great starting points to get a good picture of the status quo and obtain enough information to make decisions based on data, instead of jumping to conclusions to make decisions based on vague assumptions,&#8221; Ruzzi explains.</p>



<p>However, Ruzzi cautions that &#8220;the data that needs to be collected on the actions is not trivial, and even with the data, assumptions and trade-offs will be necessary for final decision making. Making decisions after data gathering is where the big challenge will be.&#8221;</p>



<p>In a notable move to democratise AI research, the memorandum reinforces support for the National AI Research Resource pilot programme. This initiative aims to extend AI research capabilities beyond major tech firms to universities, civil society organisations, and small businesses.</p>



<p>The NSM introduces the <a href="https://ai.gov/wp-content/uploads/2024/10/NSM-Framework-to-Advance-AI-Governance-and-Risk-Management-in-National-Security.pdf">Framework to Advance AI Governance and Risk Management in National Security</a> (PDF), which establishes comprehensive guidelines for implementing AI in national security applications. These guidelines mandate rigorous <a href="https://www.developer-tech.com/news/holistic-open-source-tools-counter-ai-development-risks/">risk assessment</a> procedures and safeguards against privacy invasions, bias, discrimination, and human rights violations.</p>



<p>Security considerations feature prominently in the framework, with Ruzzi emphasising their importance: &#8220;Cybersecurity of AI is crucial – we know that if AI is misconfigured, it can pose risks similar to misconfigurations in SaaS applications that cause confidential data to be exposed.&#8221;</p>



<p>On the international front, the memorandum builds upon recent <a href="https://www.artificialintelligence-news.com/news/global-ai-security-guidelines-endorsed-by-18-countries/">diplomatic achievements</a>, including the G7&#8217;s International Code of Conduct on AI and agreements reached at the <a href="https://www.artificialintelligence-news.com/news/uk-reveals-ai-safety-summit-opening-day-agenda/">Bletchley</a> and <a href="https://www.artificialintelligence-news.com/news/uk-and-south-korea-cohost-ai-seoul-summit/">Seoul</a> AI Safety Summits. Notably, 56 nations have endorsed the US-led Political Declaration on the Military Use of AI and Autonomy.</p>



<p>The Biden administration has also secured a diplomatic victory with the passage of the first UN General Assembly Resolution on AI, which garnered unanimous support, including co-sponsorship from China.</p>



<p>The memorandum emphasises the critical role of <a href="https://www.artificialintelligence-news.com/news/global-semiconductor-shortage-how-us-plans-close-talent-gap/">semiconductor manufacturing</a> in AI development, connecting to Biden&#8217;s earlier CHIPS Act. It directs actions to enhance chip supply chain security and diversity, ensuring American leadership in advanced computing infrastructure.</p>



<p>This latest initiative forms part of the Biden-Harris Administration&#8217;s broader strategy for responsible innovation in <a href="https://www.artificialintelligence-news.com/news/ai-sector-study-record-growth-masks-serious-challenges/">the AI sector</a>, reinforcing America&#8217;s commitment to maintaining technological leadership while upholding <a href="https://www.artificialintelligence-news.com/news/uk-signs-ai-safety-treaty-to-protect-human-rights-and-democracy/">democratic values and human rights</a>.</p>



<p><em>(Photo by <a href="https://unsplash.com/@nhuenerfuerst?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Nils Huenerfuerst</a>)</em></p>



<p><strong>See also: </strong><a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/"><strong>EU AI Act: Early prep could give businesses competitive edge</strong></a></p>



<figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="auto, (max-width: 728px) 100vw, 728px" /></a></figure>



<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href="https://www.ai-expo.net/"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href="https://intelligentautomation-conference.com/northamerica/">Intelligent Automation Conference</a>, <a href="https://www.blockchain-expo.com/">BlockX</a>,<a href="https://digitaltransformation-week.com/"> Digital Transformation Week</a>, and <a href="https://www.cybersecuritycloudexpo.com/">Cyber Security &amp; Cloud Expo</a>.</p>



<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href="https://techforge.pub/events/">here</a>.</p>
<p>The post <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">President Biden issues first National Security Memorandum on AI</a> appeared first on <a href="https://www.artificialintelligence-news.com">AI News</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
